{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7cf4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, make_scorer, f1_score, recall_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sns_palette = sns.color_palette(\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dabfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = pd.read_csv('hepatitis.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e06541cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liver_big</th>\n",
       "      <th>liver_firm</th>\n",
       "      <th>spleen_palpable</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>alk_phosphate</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>126.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  age  sex  steroid  antivirals  fatigue  malaise  anorexia  \\\n",
       "0        2   30    2      1.0           2      2.0      2.0       2.0   \n",
       "1        2   50    1      1.0           2      1.0      2.0       2.0   \n",
       "2        2   78    1      2.0           2      1.0      2.0       2.0   \n",
       "3        2   31    1      NaN           1      2.0      2.0       2.0   \n",
       "4        2   34    1      2.0           2      2.0      2.0       2.0   \n",
       "..     ...  ...  ...      ...         ...      ...      ...       ...   \n",
       "150      1   46    1      2.0           2      1.0      1.0       1.0   \n",
       "151      2   44    1      2.0           2      1.0      2.0       2.0   \n",
       "152      2   61    1      1.0           2      1.0      1.0       2.0   \n",
       "153      2   53    2      1.0           2      1.0      2.0       2.0   \n",
       "154      1   43    1      2.0           2      1.0      2.0       2.0   \n",
       "\n",
       "     liver_big  liver_firm  spleen_palpable  spiders  ascites  varices  \\\n",
       "0          1.0         2.0              2.0      2.0      2.0      2.0   \n",
       "1          1.0         2.0              2.0      2.0      2.0      2.0   \n",
       "2          2.0         2.0              2.0      2.0      2.0      2.0   \n",
       "3          2.0         2.0              2.0      2.0      2.0      2.0   \n",
       "4          2.0         2.0              2.0      2.0      2.0      2.0   \n",
       "..         ...         ...              ...      ...      ...      ...   \n",
       "150        2.0         2.0              2.0      1.0      1.0      1.0   \n",
       "151        2.0         1.0              2.0      2.0      2.0      2.0   \n",
       "152        1.0         1.0              2.0      1.0      2.0      2.0   \n",
       "153        2.0         2.0              1.0      1.0      2.0      1.0   \n",
       "154        2.0         2.0              1.0      1.0      1.0      2.0   \n",
       "\n",
       "     bilirubin  alk_phosphate   sgot  albumin  protime  histology  \n",
       "0          1.0           85.0   18.0      4.0      NaN          1  \n",
       "1          0.9          135.0   42.0      3.5      NaN          1  \n",
       "2          0.7           96.0   32.0      4.0      NaN          1  \n",
       "3          0.7           46.0   52.0      4.0     80.0          1  \n",
       "4          1.0            NaN  200.0      4.0      NaN          1  \n",
       "..         ...            ...    ...      ...      ...        ...  \n",
       "150        7.6            NaN  242.0      3.3     50.0          2  \n",
       "151        0.9          126.0  142.0      4.3      NaN          2  \n",
       "152        0.8           75.0   20.0      4.1      NaN          2  \n",
       "153        1.5           81.0   19.0      4.1     48.0          2  \n",
       "154        1.2          100.0   19.0      3.1     42.0          2  \n",
       "\n",
       "[155 rows x 20 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrn = lrn.replace('?', np.nan)\n",
    "lrn = lrn.apply(pd.to_numeric)\n",
    "lrn.columns = lrn.columns.str.replace(' ', '')\n",
    "lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e22cf3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['class', 'sex', 'steroid', 'antivirals', 'fatigue', 'malaise', \n",
    "      'anorexia', 'liver_big', 'liver_firm', 'spleen_palpable', \n",
    "     'spiders', 'ascites', 'varices', 'histology']\n",
    "for i in cats:\n",
    "    lrn[i] = lrn[i].apply(lambda x: np.nan if pd.isnull(x) else x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23ae91e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liver_big</th>\n",
       "      <th>liver_firm</th>\n",
       "      <th>spleen_palpable</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>alk_phosphate</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>126.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  age  sex  steroid  antivirals  fatigue  malaise  anorexia  \\\n",
       "0        1   30    1      0.0           1      1.0      1.0       1.0   \n",
       "1        1   50    0      0.0           1      0.0      1.0       1.0   \n",
       "2        1   78    0      1.0           1      0.0      1.0       1.0   \n",
       "3        1   31    0      NaN           0      1.0      1.0       1.0   \n",
       "4        1   34    0      1.0           1      1.0      1.0       1.0   \n",
       "..     ...  ...  ...      ...         ...      ...      ...       ...   \n",
       "150      0   46    0      1.0           1      0.0      0.0       0.0   \n",
       "151      1   44    0      1.0           1      0.0      1.0       1.0   \n",
       "152      1   61    0      0.0           1      0.0      0.0       1.0   \n",
       "153      1   53    1      0.0           1      0.0      1.0       1.0   \n",
       "154      0   43    0      1.0           1      0.0      1.0       1.0   \n",
       "\n",
       "     liver_big  liver_firm  spleen_palpable  spiders  ascites  varices  \\\n",
       "0          0.0         1.0              1.0      1.0      1.0      1.0   \n",
       "1          0.0         1.0              1.0      1.0      1.0      1.0   \n",
       "2          1.0         1.0              1.0      1.0      1.0      1.0   \n",
       "3          1.0         1.0              1.0      1.0      1.0      1.0   \n",
       "4          1.0         1.0              1.0      1.0      1.0      1.0   \n",
       "..         ...         ...              ...      ...      ...      ...   \n",
       "150        1.0         1.0              1.0      0.0      0.0      0.0   \n",
       "151        1.0         0.0              1.0      1.0      1.0      1.0   \n",
       "152        0.0         0.0              1.0      0.0      1.0      1.0   \n",
       "153        1.0         1.0              0.0      0.0      1.0      0.0   \n",
       "154        1.0         1.0              0.0      0.0      0.0      1.0   \n",
       "\n",
       "     bilirubin  alk_phosphate   sgot  albumin  protime  histology  \n",
       "0          1.0           85.0   18.0      4.0      NaN          0  \n",
       "1          0.9          135.0   42.0      3.5      NaN          0  \n",
       "2          0.7           96.0   32.0      4.0      NaN          0  \n",
       "3          0.7           46.0   52.0      4.0     80.0          0  \n",
       "4          1.0            NaN  200.0      4.0      NaN          0  \n",
       "..         ...            ...    ...      ...      ...        ...  \n",
       "150        7.6            NaN  242.0      3.3     50.0          1  \n",
       "151        0.9          126.0  142.0      4.3      NaN          1  \n",
       "152        0.8           75.0   20.0      4.1      NaN          1  \n",
       "153        1.5           81.0   19.0      4.1     48.0          1  \n",
       "154        1.2          100.0   19.0      3.1     42.0          1  \n",
       "\n",
       "[155 rows x 20 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c9740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lrn['class']\n",
    "X = lrn.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3e91cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97cc07f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['steroid', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm',\n",
       "       'spleen_palpable', 'spiders', 'ascites', 'varices', 'bilirubin',\n",
       "       'alk_phosphate', 'sgot', 'albumin', 'protime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[X.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9549d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db0101fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['steroid', 'fatigue','anorexia', 'malaise', 'liver_big', 'liver_firm',\n",
    "       'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology']] = X[['steroid', 'fatigue','anorexia', 'malaise', 'liver_big', 'liver_firm',\n",
    "       'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology']].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bdb5f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liver_big</th>\n",
       "      <th>liver_firm</th>\n",
       "      <th>spleen_palpable</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>alk_phosphate</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  steroid  antivirals  fatigue  malaise  anorexia  liver_big  \\\n",
       "0     30    1      0.0           1      1.0      1.0       1.0        0.0   \n",
       "1     50    0      0.0           1      0.0      1.0       1.0        0.0   \n",
       "2     78    0      1.0           1      0.0      1.0       1.0        1.0   \n",
       "3     31    0      1.0           0      1.0      1.0       1.0        1.0   \n",
       "4     34    0      1.0           1      1.0      1.0       1.0        1.0   \n",
       "..   ...  ...      ...         ...      ...      ...       ...        ...   \n",
       "150   46    0      1.0           1      0.0      0.0       0.0        1.0   \n",
       "151   44    0      1.0           1      0.0      1.0       1.0        1.0   \n",
       "152   61    0      0.0           1      0.0      0.0       1.0        0.0   \n",
       "153   53    1      0.0           1      0.0      1.0       1.0        1.0   \n",
       "154   43    0      1.0           1      0.0      1.0       1.0        1.0   \n",
       "\n",
       "     liver_firm  spleen_palpable  spiders  ascites  varices  bilirubin  \\\n",
       "0           1.0              1.0      1.0      1.0      1.0        1.0   \n",
       "1           1.0              1.0      1.0      1.0      1.0        0.9   \n",
       "2           1.0              1.0      1.0      1.0      1.0        0.7   \n",
       "3           1.0              1.0      1.0      1.0      1.0        0.7   \n",
       "4           1.0              1.0      1.0      1.0      1.0        1.0   \n",
       "..          ...              ...      ...      ...      ...        ...   \n",
       "150         1.0              1.0      0.0      0.0      0.0        7.6   \n",
       "151         0.0              1.0      1.0      1.0      1.0        0.9   \n",
       "152         0.0              1.0      0.0      1.0      1.0        0.8   \n",
       "153         1.0              0.0      0.0      1.0      0.0        1.5   \n",
       "154         1.0              0.0      0.0      0.0      1.0        1.2   \n",
       "\n",
       "     alk_phosphate   sgot  albumin    protime  histology  \n",
       "0        85.000000   18.0      4.0  61.852273          0  \n",
       "1       135.000000   42.0      3.5  61.852273          0  \n",
       "2        96.000000   32.0      4.0  61.852273          0  \n",
       "3        46.000000   52.0      4.0  80.000000          0  \n",
       "4       105.325397  200.0      4.0  61.852273          0  \n",
       "..             ...    ...      ...        ...        ...  \n",
       "150     105.325397  242.0      3.3  50.000000          1  \n",
       "151     126.000000  142.0      4.3  61.852273          1  \n",
       "152      75.000000   20.0      4.1  61.852273          1  \n",
       "153      81.000000   19.0      4.1  48.000000          1  \n",
       "154     100.000000   19.0      3.1  42.000000          1  \n",
       "\n",
       "[155 rows x 19 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc9182",
   "metadata": {},
   "source": [
    "### Hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7aa4d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out(model_label, model, X, y, scale=None, n=10):\n",
    "\n",
    "    # if a scaling method is given, perform scaling\n",
    "    if scale is not None:\n",
    "        model = make_pipeline(scale, model)\n",
    "\n",
    "    # dataframe for results for each split\n",
    "    results = pd.DataFrame(columns=['Split/Fold', 'Method', 'Algorithm', 'Scaling', 'Accuracy', 'Recall', 'F1-score', 'F2-score', 'Training time'])\n",
    "    #results = []\n",
    "\n",
    "    # perform the hold out method n times with n different seeds\n",
    "    for i in range(n):\n",
    "\n",
    "        # split the data into training and testing set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=i)\n",
    "\n",
    "        # train the model on the train set\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        tr_time = end - start\n",
    "\n",
    "        # predict values for the test set\n",
    "        y_predicted = model.predict(X_test)\n",
    "        \n",
    "        # calculate metrics\n",
    "        acc = accuracy_score(y_test, y_predicted)\n",
    "        r = recall_score(y_test, y_predicted)\n",
    "        f1 = f1_score(y_test, y_predicted)\n",
    "        f2 = fbeta_score(y_test, y_predicted, beta=2)\n",
    "\n",
    "        result =  {'Split/Fold': i,\n",
    "                   'Method': 'Hold out',\n",
    "                    'Algorithm': model_label, \n",
    "                    'Scaling': 'None' if scale is None else type(scale).__name__,\n",
    "                    'Accuracy': acc,\n",
    "                    'Recall': r,\n",
    "                    'F1-score': f1,\n",
    "                    'F2-score': f2,\n",
    "                    'Training time': tr_time}\n",
    "        \n",
    "        results.loc[len(results)] = result\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bf57ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_ho = pd.DataFrame(columns=['Split/Fold', 'Method', 'Algorithm', 'Scaling', 'Accuracy', 'Recall', 'F1-score', 'F2-score', 'Training time'])\n",
    "\n",
    "res_ho =  pd.concat([res_ho, hold_out(\"SVM\", SVC(), X, y)])\n",
    "res_ho =  pd.concat([res_ho, hold_out(\"SVM\", SVC(), X, y, scale=StandardScaler())])\n",
    "res_ho =  pd.concat([res_ho, hold_out(\"SVM\", SVC(), X, y, scale=MinMaxScaler())])\n",
    "\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Logistic Regression\", LogisticRegression(), X, y)])\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Logistic Regression\", LogisticRegression(), X, y, scale=StandardScaler())])\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Logistic Regression\", LogisticRegression(), X, y, scale=MinMaxScaler())])\n",
    "\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Decision Tree\", DecisionTreeClassifier(), X, y)])\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Decision Tree\", DecisionTreeClassifier(), X, y, scale=StandardScaler())])\n",
    "res_ho = pd.concat([res_ho, hold_out(\"Decision Tree\", DecisionTreeClassifier(), X, y, scale=MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "920182ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split/Fold</th>\n",
       "      <th>Method</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.950920</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.817610</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>0.003999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hold out</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.004994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split/Fold    Method      Algorithm       Scaling  Accuracy    Recall  \\\n",
       "0           0  Hold out            SVM          None  0.743590  1.000000   \n",
       "1           1  Hold out            SVM          None  0.794872  1.000000   \n",
       "2           2  Hold out            SVM          None  0.743590  1.000000   \n",
       "3           3  Hold out            SVM          None  0.820513  1.000000   \n",
       "4           4  Hold out            SVM          None  0.846154  1.000000   \n",
       "..        ...       ...            ...           ...       ...       ...   \n",
       "5           5  Hold out  Decision Tree  MinMaxScaler  0.717949  0.812500   \n",
       "6           6  Hold out  Decision Tree  MinMaxScaler  0.692308  0.741935   \n",
       "7           7  Hold out  Decision Tree  MinMaxScaler  0.641026  0.655172   \n",
       "8           8  Hold out  Decision Tree  MinMaxScaler  0.769231  0.812500   \n",
       "9           9  Hold out  Decision Tree  MinMaxScaler  0.897436  0.969697   \n",
       "\n",
       "    F1-score  F2-score  Training time  \n",
       "0   0.852941  0.935484       0.009000  \n",
       "1   0.885714  0.950920       0.003998  \n",
       "2   0.852941  0.935484       0.004000  \n",
       "3   0.901408  0.958084       0.003000  \n",
       "4   0.916667  0.964912       0.004000  \n",
       "..       ...       ...            ...  \n",
       "5   0.825397  0.817610       0.003998  \n",
       "6   0.793103  0.761589       0.004005  \n",
       "7   0.730769  0.683453       0.003999  \n",
       "8   0.852459  0.828025       0.004000  \n",
       "9   0.941176  0.958084       0.004994  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cadb0b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Decision Tree</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.084827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.060194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.787179</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.056759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.034188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.041959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.864103</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.041959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.031980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.797436</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.040901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.035857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy                              \n",
       "                                         min      mean       max       std\n",
       "Algorithm           Scaling                                               \n",
       "Decision Tree       MinMaxScaler    0.641026  0.756410  0.897436  0.084827\n",
       "                    None            0.666667  0.789744  0.871795  0.060194\n",
       "                    StandardScaler  0.692308  0.787179  0.871795  0.056759\n",
       "Logistic Regression MinMaxScaler    0.769231  0.846154  0.897436  0.034188\n",
       "                    None            0.769231  0.853846  0.897436  0.041959\n",
       "                    StandardScaler  0.769231  0.864103  0.897436  0.041959\n",
       "SVM                 MinMaxScaler    0.794872  0.846154  0.897436  0.031980\n",
       "                    None            0.743590  0.797436  0.846154  0.040901\n",
       "                    StandardScaler  0.794872  0.841026  0.897436  0.035857"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ho.groupby(['Algorithm', 'Scaling']).agg({'Accuracy': [ 'min', 'mean', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1fbc543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">F2-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Decision Tree</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.683453</td>\n",
       "      <td>0.831112</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.081628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.688406</td>\n",
       "      <td>0.859441</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.074385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.719424</td>\n",
       "      <td>0.855552</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.058606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.931446</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.022070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.026506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.859873</td>\n",
       "      <td>0.931531</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.032526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.933435</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.016581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.951237</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.011829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.934103</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.019008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    F2-score                              \n",
       "                                         min      mean       max       std\n",
       "Algorithm           Scaling                                               \n",
       "Decision Tree       MinMaxScaler    0.683453  0.831112  0.958084  0.081628\n",
       "                    None            0.688406  0.859441  0.925926  0.074385\n",
       "                    StandardScaler  0.719424  0.855552  0.925926  0.058606\n",
       "Logistic Regression MinMaxScaler    0.900000  0.931446  0.960265  0.022070\n",
       "                    None            0.886076  0.931167  0.960265  0.026506\n",
       "                    StandardScaler  0.859873  0.931531  0.966667  0.032526\n",
       "SVM                 MinMaxScaler    0.903226  0.933435  0.958084  0.016581\n",
       "                    None            0.935484  0.951237  0.964912  0.011829\n",
       "                    StandardScaler  0.897436  0.934103  0.958084  0.019008"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ho.groupby(['Algorithm', 'Scaling']).agg({'F2-score': [ 'min', 'mean', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48bfd638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=\"Algorithm\", x=\"Accuracy\",\n",
    "            hue=\"Scaling\", palette=sns_palette,\n",
    "            data=res_ho)\n",
    "plt.show()\n",
    "sns.boxplot(y=\"Algorithm\", x=\"F2-score\",\n",
    "            hue=\"Scaling\", palette=sns_palette,\n",
    "            data=res_ho)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4c48c",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "abf2b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_label, model, X, y, scale=None):\n",
    "\n",
    "    # if a scaling method is given, perform scaling\n",
    "    if scale is not None:\n",
    "        model = make_pipeline(scale, model)\n",
    "\n",
    "    # dataframe for results of each fold\n",
    "    results = pd.DataFrame(columns=['Split/Fold', 'Method', 'Algorithm', 'Scaling', 'Accuracy', 'Recall', 'F1-score', 'F2-score', 'Training time'])\n",
    "\n",
    "    cval = cross_validate(model, X, y, scoring={'accuracy': 'accuracy', \n",
    "                                               'recall': 'recall',\n",
    "                                               'f1': 'f1', \n",
    "                                               'f2': make_scorer(fbeta_score, beta=2)}, \n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    for i in range(len(cval['test_accuracy'])):\n",
    "        # fetch calculated metrics\n",
    "        acc = cval['test_accuracy'][i]\n",
    "        r = cval['test_recall'][i]\n",
    "        f1 = cval['test_f1'][i]\n",
    "        f2 = cval['test_f2'][i]\n",
    "        tr_time = cval['fit_time'][i]\n",
    "\n",
    "        result =   {'Split/Fold': i+1,\n",
    "                    'Method':'Cross-validation',\n",
    "                    'Algorithm': model_label, \n",
    "                    'Scaling': 'None' if scale is None else type(scale).__name__,\n",
    "                    'Accuracy': acc,\n",
    "                    'Recall': r,\n",
    "                    'F1-score': f1,\n",
    "                    'F2-score': f2,\n",
    "                    'Training time': tr_time}\n",
    "        results.loc[len(results)] = result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7206e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cv = pd.DataFrame(columns=['Split/Fold', 'Method', 'Algorithm', 'Scaling', 'Accuracy', 'Recall', 'F1-score', 'F2-score', 'Training time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f966427",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cv =  pd.concat([res_cv, cross_validation(\"SVM\", SVC(), X, y)])\n",
    "res_cv =  pd.concat([res_cv, cross_validation(\"SVM\", SVC(), X, y, scale=StandardScaler())])\n",
    "res_cv =  pd.concat([res_cv, cross_validation(\"SVM\", SVC(), X, y, scale=MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3c65abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cv = pd.concat([res_cv, cross_validation(\"Logistic Regression\", LogisticRegression(), X, y)])\n",
    "res_cv = pd.concat([res_cv, cross_validation(\"Logistic Regression\", LogisticRegression(), X, y, scale=StandardScaler())])\n",
    "res_cv = pd.concat([res_cv, cross_validation(\"Logistic Regression\", LogisticRegression(), X, y, scale=MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "637d2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cv = pd.concat([res_cv, cross_validation(\"Decision Tree\", DecisionTreeClassifier(), X, y)])\n",
    "res_cv = pd.concat([res_cv, cross_validation(\"Decision Tree\", DecisionTreeClassifier(), X, y, scale=StandardScaler())])\n",
    "res_cv = pd.concat([res_cv, cross_validation(\"Decision Tree\", DecisionTreeClassifier(), X, y, scale=MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28b615d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split/Fold</th>\n",
       "      <th>Method</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.006991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.005994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.009001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.009003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.008996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.008003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.010013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.011001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.023001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.030001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.015008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.013005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.011998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.010988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.012999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.012991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.005996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.003991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.005996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.010003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.008995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.007998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Split/Fold            Method            Algorithm         Scaling  Accuracy  \\\n",
       "0          1  Cross-validation                  SVM            None  0.806452   \n",
       "1          2  Cross-validation                  SVM            None  0.806452   \n",
       "2          3  Cross-validation                  SVM            None  0.806452   \n",
       "3          4  Cross-validation                  SVM            None  0.774194   \n",
       "4          5  Cross-validation                  SVM            None  0.774194   \n",
       "0          1  Cross-validation                  SVM  StandardScaler  0.838710   \n",
       "1          2  Cross-validation                  SVM  StandardScaler  0.903226   \n",
       "2          3  Cross-validation                  SVM  StandardScaler  0.903226   \n",
       "3          4  Cross-validation                  SVM  StandardScaler  0.870968   \n",
       "4          5  Cross-validation                  SVM  StandardScaler  0.774194   \n",
       "0          1  Cross-validation                  SVM    MinMaxScaler  0.806452   \n",
       "1          2  Cross-validation                  SVM    MinMaxScaler  0.870968   \n",
       "2          3  Cross-validation                  SVM    MinMaxScaler  0.903226   \n",
       "3          4  Cross-validation                  SVM    MinMaxScaler  0.903226   \n",
       "4          5  Cross-validation                  SVM    MinMaxScaler  0.741935   \n",
       "0          1  Cross-validation  Logistic Regression            None  0.838710   \n",
       "1          2  Cross-validation  Logistic Regression            None  0.838710   \n",
       "2          3  Cross-validation  Logistic Regression            None  0.870968   \n",
       "3          4  Cross-validation  Logistic Regression            None  0.870968   \n",
       "4          5  Cross-validation  Logistic Regression            None  0.838710   \n",
       "0          1  Cross-validation  Logistic Regression  StandardScaler  0.838710   \n",
       "1          2  Cross-validation  Logistic Regression  StandardScaler  0.838710   \n",
       "2          3  Cross-validation  Logistic Regression  StandardScaler  0.870968   \n",
       "3          4  Cross-validation  Logistic Regression  StandardScaler  0.870968   \n",
       "4          5  Cross-validation  Logistic Regression  StandardScaler  0.806452   \n",
       "0          1  Cross-validation  Logistic Regression    MinMaxScaler  0.806452   \n",
       "1          2  Cross-validation  Logistic Regression    MinMaxScaler  0.903226   \n",
       "2          3  Cross-validation  Logistic Regression    MinMaxScaler  0.838710   \n",
       "3          4  Cross-validation  Logistic Regression    MinMaxScaler  0.903226   \n",
       "4          5  Cross-validation  Logistic Regression    MinMaxScaler  0.741935   \n",
       "0          1  Cross-validation        Decision Tree            None  0.774194   \n",
       "1          2  Cross-validation        Decision Tree            None  0.677419   \n",
       "2          3  Cross-validation        Decision Tree            None  0.838710   \n",
       "3          4  Cross-validation        Decision Tree            None  0.774194   \n",
       "4          5  Cross-validation        Decision Tree            None  0.774194   \n",
       "0          1  Cross-validation        Decision Tree  StandardScaler  0.774194   \n",
       "1          2  Cross-validation        Decision Tree  StandardScaler  0.677419   \n",
       "2          3  Cross-validation        Decision Tree  StandardScaler  0.838710   \n",
       "3          4  Cross-validation        Decision Tree  StandardScaler  0.741935   \n",
       "4          5  Cross-validation        Decision Tree  StandardScaler  0.806452   \n",
       "0          1  Cross-validation        Decision Tree    MinMaxScaler  0.741935   \n",
       "1          2  Cross-validation        Decision Tree    MinMaxScaler  0.677419   \n",
       "2          3  Cross-validation        Decision Tree    MinMaxScaler  0.838710   \n",
       "3          4  Cross-validation        Decision Tree    MinMaxScaler  0.741935   \n",
       "4          5  Cross-validation        Decision Tree    MinMaxScaler  0.806452   \n",
       "\n",
       "     Recall  F1-score  F2-score  Training time  \n",
       "0  1.000000  0.892857  0.954198       0.006991  \n",
       "1  1.000000  0.892857  0.954198       0.005998  \n",
       "2  1.000000  0.892857  0.954198       0.004997  \n",
       "3  1.000000  0.872727  0.944882       0.005998  \n",
       "4  1.000000  0.872727  0.944882       0.005994  \n",
       "0  1.000000  0.909091  0.961538       0.009001  \n",
       "1  0.960000  0.941176  0.952381       0.009003  \n",
       "2  1.000000  0.943396  0.976563       0.009995  \n",
       "3  0.958333  0.920000  0.942623       0.008996  \n",
       "4  0.750000  0.837209  0.782609       0.008003  \n",
       "0  1.000000  0.892857  0.954198       0.010013  \n",
       "1  0.960000  0.923077  0.944882       0.011001  \n",
       "2  1.000000  0.943396  0.976563       0.011003  \n",
       "3  0.958333  0.938776  0.950413       0.010000  \n",
       "4  0.708333  0.809524  0.745614       0.010995  \n",
       "0  1.000000  0.909091  0.961538       0.023001  \n",
       "1  0.960000  0.905660  0.937500       0.038000  \n",
       "2  0.960000  0.923077  0.944882       0.030001  \n",
       "3  0.875000  0.913043  0.889831       0.037000  \n",
       "4  0.833333  0.888889  0.854701       0.034000  \n",
       "0  1.000000  0.909091  0.961538       0.015008  \n",
       "1  0.960000  0.905660  0.937500       0.015010  \n",
       "2  0.960000  0.923077  0.944882       0.013005  \n",
       "3  0.916667  0.916667  0.916667       0.011998  \n",
       "4  0.791667  0.863636  0.818966       0.010988  \n",
       "0  1.000000  0.892857  0.954198       0.012999  \n",
       "1  0.960000  0.941176  0.952381       0.013000  \n",
       "2  0.960000  0.905660  0.937500       0.012000  \n",
       "3  0.958333  0.938776  0.950413       0.012991  \n",
       "4  0.708333  0.809524  0.745614       0.017000  \n",
       "0  0.960000  0.872727  0.923077       0.005996  \n",
       "1  0.720000  0.782609  0.743802       0.003991  \n",
       "2  0.840000  0.893617  0.860656       0.005996  \n",
       "3  0.833333  0.851064  0.840336       0.005003  \n",
       "4  0.791667  0.844444  0.811966       0.004998  \n",
       "0  0.960000  0.872727  0.923077       0.008998  \n",
       "1  0.720000  0.782609  0.743802       0.008002  \n",
       "2  0.840000  0.893617  0.860656       0.009000  \n",
       "3  0.791667  0.826087  0.805085       0.008998  \n",
       "4  0.791667  0.863636  0.818966       0.010003  \n",
       "0  0.920000  0.851852  0.891473       0.008995  \n",
       "1  0.720000  0.782609  0.743802       0.007998  \n",
       "2  0.840000  0.893617  0.860656       0.009000  \n",
       "3  0.875000  0.840000  0.860656       0.009000  \n",
       "4  0.791667  0.863636  0.818966       0.008998  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b38840ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Decision Tree</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.062883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.057705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.062050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.068430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.017668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.026989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.069934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.017668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.053978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy                              \n",
       "                                         min      mean       max       std\n",
       "Algorithm           Scaling                                               \n",
       "Decision Tree       MinMaxScaler    0.677419  0.761290  0.838710  0.062883\n",
       "                    None            0.677419  0.767742  0.838710  0.057705\n",
       "                    StandardScaler  0.677419  0.767742  0.838710  0.062050\n",
       "Logistic Regression MinMaxScaler    0.741935  0.838710  0.903226  0.068430\n",
       "                    None            0.838710  0.851613  0.870968  0.017668\n",
       "                    StandardScaler  0.806452  0.845161  0.870968  0.026989\n",
       "SVM                 MinMaxScaler    0.741935  0.845161  0.903226  0.069934\n",
       "                    None            0.774194  0.793548  0.806452  0.017668\n",
       "                    StandardScaler  0.774194  0.858065  0.903226  0.053978"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cv.groupby(['Algorithm', 'Scaling']).agg({'Accuracy': [ 'min', 'mean', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fd43c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">F2-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Decision Tree</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.835110</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.057183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.835967</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.065741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.066662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.908021</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.091025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.044154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.915911</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.056538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.914334</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.095083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.950472</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.005103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.923143</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.079549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    F2-score                              \n",
       "                                         min      mean       max       std\n",
       "Algorithm           Scaling                                               \n",
       "Decision Tree       MinMaxScaler    0.743802  0.835110  0.891473  0.057183\n",
       "                    None            0.743802  0.835967  0.923077  0.065741\n",
       "                    StandardScaler  0.743802  0.830317  0.923077  0.066662\n",
       "Logistic Regression MinMaxScaler    0.745614  0.908021  0.954198  0.091025\n",
       "                    None            0.854701  0.917690  0.961538  0.044154\n",
       "                    StandardScaler  0.818966  0.915911  0.961538  0.056538\n",
       "SVM                 MinMaxScaler    0.745614  0.914334  0.976563  0.095083\n",
       "                    None            0.944882  0.950472  0.954198  0.005103\n",
       "                    StandardScaler  0.782609  0.923143  0.976563  0.079549"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cv.groupby(['Algorithm', 'Scaling']).agg({'F2-score': [ 'min', 'mean', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c8c6902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=\"Algorithm\", x=\"Accuracy\",\n",
    "            hue=\"Scaling\", palette=sns_palette,\n",
    "            data=res_cv)\n",
    "plt.show()\n",
    "sns.boxplot(y=\"Algorithm\", x=\"F2-score\",\n",
    "            hue=\"Scaling\", palette=sns_palette,\n",
    "            data=res_cv)\n",
    "plt.savefig('hepatitis-sc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7889824",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_joint =  pd.concat([res_ho, res_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a600cacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=\"Algorithm\", x=\"Accuracy\",\n",
    "            hue=\"Method\", palette=sns_palette,\n",
    "            data=res_joint)\n",
    "plt.show()\n",
    "sns.boxplot(y=\"Algorithm\", x=\"F2-score\",\n",
    "            hue=\"Method\", palette=sns_palette,\n",
    "            data=res_joint)\n",
    "plt.savefig('hepatitis-method.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292e11d",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9db0780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = lambda x: x.split(\"__\",1)[1]\n",
    "\n",
    "def plot_grid_search(scores, hyperparameters, scale=None):\n",
    "    data = pd.DataFrame(hyperparameters)\n",
    "    \n",
    "    # fix feature names\n",
    "    if scale is not None:\n",
    "        data.columns = [preproc(col) for col in data.columns.values] \n",
    "        \n",
    "    data['mean_test_score'] = scores\n",
    "    \n",
    "    # fix categorical values\n",
    "    categorical = data.select_dtypes(exclude='number').columns.values\n",
    "    for c in categorical:\n",
    "        oe = OrdinalEncoder()\n",
    "        data[[c]] = oe.fit_transform(data[[c]])\n",
    "\n",
    "    fig = px.parallel_coordinates(data, color=data.columns.values[-1], color_continuous_scale=px.colors.sequential.Viridis\n",
    "                                 )\n",
    "    fig.show()\n",
    "\n",
    "def grid_search(model, X, y, hyperparams, scoring, plot=True, metric=None, scale=None):\n",
    "    if scale is not None:\n",
    "        model = make_pipeline(scale, model)\n",
    "    else:\n",
    "        hyperparams = {preproc(k): v for k, v in hyperparams.items()}\n",
    "    search = GridSearchCV(model, param_grid=hyperparams)\n",
    "    search.fit(X,y)\n",
    "    scores = search.cv_results_['mean_test_score']\n",
    "    hyperparameters = search.cv_results_['params']\n",
    "    if plot:\n",
    "        plot_grid_search(scores, hyperparameters, scale)\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb04675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm = {\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "    }\n",
    "\n",
    "params_lr = {\n",
    "    'logisticregression__penalty': ['none','l1', 'l2', 'elasticnet'],\n",
    "    'logisticregression__C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'logisticregression__solver': ['saga', 'sag', 'lbfgs']\n",
    "    }\n",
    "\n",
    "params_dt = {\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "    'decisiontreeclassifier__max_depth': [None, 5, 10, 15],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 5, 10],\n",
    "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'decisiontreeclassifier__max_features': ['sqrt', 'log2'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0.1, 0.01, 0.001, 0.0001, 0],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "511ec0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a952c0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "C",
           "values": [
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100
           ]
          },
          {
           "label": "gamma",
           "values": [
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            10,
            10,
            10,
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            10,
            10,
            10,
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            10,
            10,
            10,
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            10,
            10,
            10,
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            10,
            10,
            10
           ]
          },
          {
           "label": "kernel",
           "values": [
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            0,
            1,
            2
           ]
          },
          {
           "label": "mean_test_score",
           "values": [
            0.8193548387096774,
            0.7935483870967742,
            0.7935483870967742,
            0.8193548387096774,
            0.7935483870967742,
            0.7935483870967742,
            0.8193548387096774,
            0.8064516129032258,
            0.7935483870967742,
            0.8193548387096774,
            0.8193548387096774,
            0.7935483870967742,
            0.8193548387096774,
            0.8193548387096774,
            0.7935483870967742,
            0.8258064516129032,
            0.7935483870967742,
            0.7935483870967742,
            0.8258064516129032,
            0.7935483870967742,
            0.7935483870967742,
            0.8258064516129032,
            0.8451612903225806,
            0.7935483870967742,
            0.8258064516129032,
            0.8193548387096774,
            0.7935483870967742,
            0.8258064516129032,
            0.8193548387096774,
            0.7935483870967742,
            0.8129032258064516,
            0.7935483870967742,
            0.7935483870967742,
            0.8129032258064516,
            0.7935483870967742,
            0.8451612903225806,
            0.8129032258064516,
            0.8451612903225806,
            0.8516129032258064,
            0.8129032258064516,
            0.8193548387096774,
            0.7935483870967742,
            0.8129032258064516,
            0.8193548387096774,
            0.7935483870967742,
            0.832258064516129,
            0.7935483870967742,
            0.8258064516129032,
            0.832258064516129,
            0.8064516129032258,
            0.8193548387096774,
            0.832258064516129,
            0.8193548387096774,
            0.864516129032258,
            0.832258064516129,
            0.8193548387096774,
            0.7935483870967742,
            0.832258064516129,
            0.8193548387096774,
            0.7935483870967742,
            0.832258064516129,
            0.7935483870967742,
            0.8129032258064516,
            0.832258064516129,
            0.8451612903225806,
            0.8387096774193548,
            0.832258064516129,
            0.8193548387096774,
            0.864516129032258,
            0.832258064516129,
            0.8193548387096774,
            0.7935483870967742,
            0.832258064516129,
            0.8193548387096774,
            0.7935483870967742
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           0.8193548387096774,
           0.7935483870967742,
           0.7935483870967742,
           0.8193548387096774,
           0.7935483870967742,
           0.7935483870967742,
           0.8193548387096774,
           0.8064516129032258,
           0.7935483870967742,
           0.8193548387096774,
           0.8193548387096774,
           0.7935483870967742,
           0.8193548387096774,
           0.8193548387096774,
           0.7935483870967742,
           0.8258064516129032,
           0.7935483870967742,
           0.7935483870967742,
           0.8258064516129032,
           0.7935483870967742,
           0.7935483870967742,
           0.8258064516129032,
           0.8451612903225806,
           0.7935483870967742,
           0.8258064516129032,
           0.8193548387096774,
           0.7935483870967742,
           0.8258064516129032,
           0.8193548387096774,
           0.7935483870967742,
           0.8129032258064516,
           0.7935483870967742,
           0.7935483870967742,
           0.8129032258064516,
           0.7935483870967742,
           0.8451612903225806,
           0.8129032258064516,
           0.8451612903225806,
           0.8516129032258064,
           0.8129032258064516,
           0.8193548387096774,
           0.7935483870967742,
           0.8129032258064516,
           0.8193548387096774,
           0.7935483870967742,
           0.832258064516129,
           0.7935483870967742,
           0.8258064516129032,
           0.832258064516129,
           0.8064516129032258,
           0.8193548387096774,
           0.832258064516129,
           0.8193548387096774,
           0.864516129032258,
           0.832258064516129,
           0.8193548387096774,
           0.7935483870967742,
           0.832258064516129,
           0.8193548387096774,
           0.7935483870967742,
           0.832258064516129,
           0.7935483870967742,
           0.8129032258064516,
           0.832258064516129,
           0.8451612903225806,
           0.8387096774193548,
           0.832258064516129,
           0.8193548387096774,
           0.864516129032258,
           0.832258064516129,
           0.8193548387096774,
           0.7935483870967742,
           0.832258064516129,
           0.8193548387096774,
           0.7935483870967742
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "mean_test_score"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6ed4799b-56b1-4e0f-bdc8-4ce4033d9a6d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6ed4799b-56b1-4e0f-bdc8-4ce4033d9a6d\")) {                    Plotly.newPlot(                        \"6ed4799b-56b1-4e0f-bdc8-4ce4033d9a6d\",                        [{\"dimensions\":[{\"label\":\"C\",\"values\":[0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0]},{\"label\":\"gamma\",\"values\":[0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1.0,1.0,1.0,10.0,10.0,10.0,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1.0,1.0,1.0,10.0,10.0,10.0,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1.0,1.0,1.0,10.0,10.0,10.0,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1.0,1.0,1.0,10.0,10.0,10.0,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1.0,1.0,1.0,10.0,10.0,10.0]},{\"label\":\"kernel\",\"values\":[0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0,0.0,1.0,2.0]},{\"label\":\"mean_test_score\",\"values\":[0.8193548387096774,0.7935483870967742,0.7935483870967742,0.8193548387096774,0.7935483870967742,0.7935483870967742,0.8193548387096774,0.8064516129032258,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8258064516129032,0.8451612903225806,0.7935483870967742,0.8258064516129032,0.8193548387096774,0.7935483870967742,0.8258064516129032,0.8193548387096774,0.7935483870967742,0.8129032258064516,0.7935483870967742,0.7935483870967742,0.8129032258064516,0.7935483870967742,0.8451612903225806,0.8129032258064516,0.8451612903225806,0.8516129032258064,0.8129032258064516,0.8193548387096774,0.7935483870967742,0.8129032258064516,0.8193548387096774,0.7935483870967742,0.832258064516129,0.7935483870967742,0.8258064516129032,0.832258064516129,0.8064516129032258,0.8193548387096774,0.832258064516129,0.8193548387096774,0.864516129032258,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.7935483870967742,0.8129032258064516,0.832258064516129,0.8451612903225806,0.8387096774193548,0.832258064516129,0.8193548387096774,0.864516129032258,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.8193548387096774,0.7935483870967742]}],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"line\":{\"color\":[0.8193548387096774,0.7935483870967742,0.7935483870967742,0.8193548387096774,0.7935483870967742,0.7935483870967742,0.8193548387096774,0.8064516129032258,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8258064516129032,0.8451612903225806,0.7935483870967742,0.8258064516129032,0.8193548387096774,0.7935483870967742,0.8258064516129032,0.8193548387096774,0.7935483870967742,0.8129032258064516,0.7935483870967742,0.7935483870967742,0.8129032258064516,0.7935483870967742,0.8451612903225806,0.8129032258064516,0.8451612903225806,0.8516129032258064,0.8129032258064516,0.8193548387096774,0.7935483870967742,0.8129032258064516,0.8193548387096774,0.7935483870967742,0.832258064516129,0.7935483870967742,0.8258064516129032,0.832258064516129,0.8064516129032258,0.8193548387096774,0.832258064516129,0.8193548387096774,0.864516129032258,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.7935483870967742,0.8129032258064516,0.832258064516129,0.8451612903225806,0.8387096774193548,0.832258064516129,0.8193548387096774,0.864516129032258,0.832258064516129,0.8193548387096774,0.7935483870967742,0.832258064516129,0.8193548387096774,0.7935483870967742],\"coloraxis\":\"coloraxis\"},\"name\":\"\",\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"mean_test_score\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6ed4799b-56b1-4e0f-bdc8-4ce4033d9a6d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm = grid_search(SVC(), X, y, hyperparams = params_svm, scoring=f2, scale=StandardScaler())\n",
    "best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a81e0e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning:\n",
      "\n",
      "\n",
      "175 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning:\n",
      "\n",
      "One or more of the test scores are non-finite: [0.84516129 0.84516129 0.84516129 0.79354839        nan        nan\n",
      " 0.79354839 0.79354839 0.79354839        nan        nan        nan\n",
      " 0.83870968 0.84516129 0.84516129 0.79354839        nan        nan\n",
      " 0.79354839 0.79354839 0.79354839        nan        nan        nan\n",
      " 0.84516129 0.84516129 0.84516129 0.79354839        nan        nan\n",
      " 0.79354839 0.79354839 0.79354839        nan        nan        nan\n",
      " 0.83870968 0.84516129 0.84516129 0.79354839        nan        nan\n",
      " 0.79354839 0.79354839 0.79354839        nan        nan        nan\n",
      " 0.84516129 0.84516129 0.84516129 0.79354839        nan        nan\n",
      " 0.8        0.8        0.8               nan        nan        nan\n",
      " 0.83870968 0.84516129 0.84516129 0.81290323        nan        nan\n",
      " 0.83870968 0.83870968 0.83870968        nan        nan        nan\n",
      " 0.83870968 0.84516129 0.84516129 0.83870968        nan        nan\n",
      " 0.82580645 0.82580645 0.82580645        nan        nan        nan]\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "C:\\Users\\38599\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "C",
           "values": [
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            1e-05,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10
           ]
          },
          {
           "label": "penalty",
           "values": [
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0,
            3,
            3,
            3,
            1,
            1,
            1,
            2,
            2,
            2,
            0,
            0,
            0
           ]
          },
          {
           "label": "solver",
           "values": [
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0,
            2,
            1,
            0
           ]
          },
          {
           "label": "mean_test_score",
           "values": [
            0.8451612903225806,
            0.8451612903225806,
            0.8451612903225806,
            0.7935483870967742,
            null,
            null,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            null,
            null,
            null,
            0.8387096774193548,
            0.8451612903225806,
            0.8451612903225806,
            0.7935483870967742,
            null,
            null,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            null,
            null,
            null,
            0.8451612903225806,
            0.8451612903225806,
            0.8451612903225806,
            0.7935483870967742,
            null,
            null,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            null,
            null,
            null,
            0.8387096774193548,
            0.8451612903225806,
            0.8451612903225806,
            0.7935483870967742,
            null,
            null,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            null,
            null,
            null,
            0.8451612903225806,
            0.8451612903225806,
            0.8451612903225806,
            0.7935483870967742,
            null,
            null,
            0.8,
            0.8,
            0.8,
            null,
            null,
            null,
            0.8387096774193548,
            0.8451612903225806,
            0.8451612903225806,
            0.8129032258064516,
            null,
            null,
            0.8387096774193548,
            0.8387096774193548,
            0.8387096774193548,
            null,
            null,
            null,
            0.8387096774193548,
            0.8451612903225806,
            0.8451612903225806,
            0.8387096774193548,
            null,
            null,
            0.8258064516129032,
            0.8258064516129032,
            0.8258064516129032,
            null,
            null,
            null
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           0.8451612903225806,
           0.8451612903225806,
           0.8451612903225806,
           0.7935483870967742,
           null,
           null,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           null,
           null,
           null,
           0.8387096774193548,
           0.8451612903225806,
           0.8451612903225806,
           0.7935483870967742,
           null,
           null,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           null,
           null,
           null,
           0.8451612903225806,
           0.8451612903225806,
           0.8451612903225806,
           0.7935483870967742,
           null,
           null,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           null,
           null,
           null,
           0.8387096774193548,
           0.8451612903225806,
           0.8451612903225806,
           0.7935483870967742,
           null,
           null,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           null,
           null,
           null,
           0.8451612903225806,
           0.8451612903225806,
           0.8451612903225806,
           0.7935483870967742,
           null,
           null,
           0.8,
           0.8,
           0.8,
           null,
           null,
           null,
           0.8387096774193548,
           0.8451612903225806,
           0.8451612903225806,
           0.8129032258064516,
           null,
           null,
           0.8387096774193548,
           0.8387096774193548,
           0.8387096774193548,
           null,
           null,
           null,
           0.8387096774193548,
           0.8451612903225806,
           0.8451612903225806,
           0.8387096774193548,
           null,
           null,
           0.8258064516129032,
           0.8258064516129032,
           0.8258064516129032,
           null,
           null,
           null
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "mean_test_score"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"74c3e6db-0330-487a-8f85-716a3d03458f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"74c3e6db-0330-487a-8f85-716a3d03458f\")) {                    Plotly.newPlot(                        \"74c3e6db-0330-487a-8f85-716a3d03458f\",                        [{\"dimensions\":[{\"label\":\"C\",\"values\":[1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0]},{\"label\":\"penalty\",\"values\":[3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0,3.0,3.0,3.0,1.0,1.0,1.0,2.0,2.0,2.0,0.0,0.0,0.0]},{\"label\":\"solver\",\"values\":[2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0,2.0,1.0,0.0]},{\"label\":\"mean_test_score\",\"values\":[0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.8,0.8,0.8,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.8129032258064516,null,null,0.8387096774193548,0.8387096774193548,0.8387096774193548,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.8387096774193548,null,null,0.8258064516129032,0.8258064516129032,0.8258064516129032,null,null,null]}],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"line\":{\"color\":[0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.7935483870967742,0.7935483870967742,0.7935483870967742,null,null,null,0.8451612903225806,0.8451612903225806,0.8451612903225806,0.7935483870967742,null,null,0.8,0.8,0.8,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.8129032258064516,null,null,0.8387096774193548,0.8387096774193548,0.8387096774193548,null,null,null,0.8387096774193548,0.8451612903225806,0.8451612903225806,0.8387096774193548,null,null,0.8258064516129032,0.8258064516129032,0.8258064516129032,null,null,null],\"coloraxis\":\"coloraxis\"},\"name\":\"\",\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"mean_test_score\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('74c3e6db-0330-487a-8f85-716a3d03458f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1e-05,\n",
       " 'logisticregression__penalty': 'none',\n",
       " 'logisticregression__solver': 'saga'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_search(LogisticRegression(), X, y, hyperparams = params_lr, scoring=f2, scale=MinMaxScaler())\n",
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51ee1047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "ccp_alpha",
           "values": [
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.1,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0.0001,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "criterion",
           "values": [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "max_depth",
           "values": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15,
            15
           ]
          },
          {
           "label": "max_features",
           "values": [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "min_samples_leaf",
           "values": [
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            1,
            1,
            1,
            2,
            2,
            2,
            4,
            4,
            4
           ]
          },
          {
           "label": "min_samples_split",
           "values": [
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10,
            2,
            5,
            10
           ]
          },
          {
           "label": "mean_test_score",
           "values": [
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.7935483870967742,
            0.8,
            0.8193548387096774,
            0.7935483870967742,
            0.7741935483870966,
            0.7806451612903225,
            0.7935483870967742,
            0.8,
            0.8,
            0.8,
            0.7935483870967742,
            0.8064516129032258,
            0.7935483870967742,
            0.7806451612903225,
            0.8,
            0.7419354838709677,
            0.7677419354838708,
            0.7741935483870966,
            0.7935483870967742,
            0.7935483870967742,
            0.7677419354838708,
            0.7741935483870966,
            0.7870967741935484,
            0.7935483870967742,
            0.8,
            0.7935483870967742,
            0.8129032258064516,
            0.7612903225806451,
            0.7935483870967742,
            0.8,
            0.8064516129032258,
            0.7741935483870966,
            0.7935483870967742,
            0.7935483870967742,
            0.8064516129032258,
            0.7806451612903226,
            0.8064516129032258,
            0.8,
            0.8064516129032258,
            0.7483870967741935,
            0.8193548387096774,
            0.8,
            0.7677419354838708,
            0.8,
            0.7419354838709677,
            0.8,
            0.7935483870967742,
            0.8193548387096774,
            0.8193548387096774,
            0.7935483870967742,
            0.8,
            0.7935483870967742,
            0.7741935483870966,
            0.7806451612903225,
            0.7935483870967742,
            0.7935483870967742,
            0.7741935483870966,
            0.7935483870967742,
            0.8064516129032258,
            0.7677419354838708,
            0.8193548387096774,
            0.8,
            0.8,
            0.7935483870967742,
            0.7935483870967742,
            0.8064516129032258,
            0.7935483870967742,
            0.7677419354838708,
            0.761290322580645,
            0.7548387096774192,
            0.7935483870967742,
            0.7806451612903225,
            0.7935483870967742,
            0.7935483870967742,
            0.7677419354838708,
            0.7548387096774193,
            0.8387096774193548,
            0.8064516129032258,
            0.7870967741935483,
            0.8387096774193548,
            0.8258064516129032,
            0.8387096774193548,
            0.7935483870967742,
            0.8129032258064516,
            0.8258064516129032,
            0.7870967741935484,
            0.8,
            0.7935483870967742,
            0.8,
            0.7741935483870968,
            0.7612903225806451,
            0.8129032258064516,
            0.7870967741935483,
            0.8,
            0.8064516129032258,
            0.8193548387096774,
            0.8258064516129032,
            0.7612903225806451,
            0.8064516129032258,
            0.832258064516129,
            0.7999999999999999,
            0.7677419354838709,
            0.8387096774193548,
            0.7741935483870968,
            0.8,
            0.7612903225806451,
            0.8451612903225806,
            0.7548387096774193,
            0.7935483870967742,
            0.767741935483871,
            0.832258064516129,
            0.8129032258064516,
            0.8064516129032258,
            0.8064516129032258,
            0.7870967741935484,
            0.7741935483870968,
            0.7935483870967742,
            0.7870967741935483,
            0.761290322580645,
            0.7870967741935483,
            0.7870967741935484,
            0.8129032258064516,
            0.832258064516129,
            0.8,
            0.832258064516129,
            0.7806451612903226,
            0.7741935483870968,
            0.7935483870967742,
            0.7870967741935483,
            0.8064516129032258,
            0.767741935483871,
            0.8064516129032258,
            0.832258064516129,
            0.7935483870967742,
            0.8129032258064516,
            0.8,
            0.7741935483870968,
            0.7935483870967742,
            0.7612903225806451,
            0.832258064516129,
            0.8258064516129032,
            0.8516129032258064,
            0.7741935483870968,
            0.8451612903225806,
            0.7741935483870968,
            0.8129032258064516,
            0.7870967741935484,
            0.7225806451612903,
            0.7870967741935484,
            0.7677419354838708,
            0.8258064516129032,
            0.7870967741935483,
            0.8258064516129032,
            0.8129032258064516,
            0.8129032258064516,
            0.7354838709677418,
            0.8258064516129032,
            0.7806451612903226,
            0.8516129032258064,
            0.832258064516129,
            0.8,
            0.7548387096774193,
            0.7806451612903226,
            0.7999999999999999,
            0.8258064516129032,
            0.7677419354838709,
            0.8129032258064516,
            0.7548387096774193,
            0.7806451612903226,
            0.8451612903225806,
            0.7290322580645161,
            0.8129032258064516,
            0.8,
            0.8387096774193548,
            0.7096774193548387,
            0.7741935483870968,
            0.7870967741935484,
            0.7548387096774193,
            0.8387096774193548,
            0.7806451612903226,
            0.832258064516129,
            0.7870967741935483,
            0.7935483870967742,
            0.7419354838709677,
            0.7870967741935484,
            0.7870967741935484,
            0.8129032258064516,
            0.8129032258064516,
            0.8387096774193548,
            0.8516129032258064,
            0.7870967741935484,
            0.7677419354838709,
            0.7870967741935484,
            0.7612903225806452,
            0.8064516129032258,
            0.8064516129032258,
            0.7741935483870968,
            0.7548387096774192,
            0.7806451612903225,
            0.7612903225806452,
            0.7612903225806452,
            0.7870967741935484,
            0.7870967741935483,
            0.7806451612903226,
            0.8064516129032258,
            0.7806451612903226,
            0.7935483870967741,
            0.8387096774193548,
            0.7870967741935484,
            0.7741935483870968,
            0.7677419354838708,
            0.7548387096774193,
            0.7741935483870968,
            0.8387096774193548,
            0.7741935483870968,
            0.7806451612903226,
            0.7870967741935484,
            0.7290322580645161,
            0.7935483870967741,
            0.7483870967741936,
            0.7870967741935483,
            0.7483870967741936,
            0.8129032258064516,
            0.8387096774193548,
            0.832258064516129,
            0.7354838709677419,
            0.7548387096774194,
            0.7225806451612902,
            0.7741935483870968,
            0.729032258064516,
            0.7612903225806451,
            0.7741935483870966,
            0.7612903225806451,
            0.7935483870967741,
            0.8193548387096774,
            0.8064516129032258,
            0.7999999999999999,
            0.7806451612903225,
            0.7548387096774193,
            0.832258064516129,
            0.7612903225806451,
            0.7741935483870968,
            0.7870967741935484,
            0.7483870967741935,
            0.7935483870967742,
            0.7612903225806451,
            0.8580645161290322,
            0.7870967741935483,
            0.8064516129032258,
            0.8064516129032258,
            0.7612903225806451,
            0.8064516129032258,
            0.7935483870967742,
            0.7806451612903226,
            0.7483870967741935,
            0.8,
            0.8,
            0.7677419354838709,
            0.832258064516129,
            0.7548387096774193,
            0.7612903225806451,
            0.8387096774193548,
            0.8064516129032258,
            0.8193548387096774,
            0.7483870967741936,
            0.7935483870967742,
            0.7741935483870968,
            0.7806451612903225,
            0.7741935483870968,
            0.7870967741935483,
            0.7935483870967742,
            0.7935483870967742,
            0.7483870967741936,
            0.7677419354838709,
            0.7806451612903226,
            0.7548387096774193,
            0.8,
            0.7999999999999999,
            0.8064516129032258,
            0.7935483870967742,
            0.8,
            0.7419354838709677,
            0.7612903225806451,
            0.767741935483871,
            0.7483870967741935,
            0.7612903225806451,
            0.8064516129032258,
            0.7612903225806451,
            0.7999999999999999,
            0.8129032258064516,
            0.7225806451612902,
            0.729032258064516,
            0.7935483870967742,
            0.7741935483870968,
            0.7677419354838709,
            0.7806451612903226,
            0.8,
            0.832258064516129,
            0.8064516129032258,
            0.7612903225806451,
            0.8,
            0.7870967741935484,
            0.7806451612903226,
            0.767741935483871,
            0.8129032258064516,
            0.7548387096774194,
            0.8064516129032258,
            0.8,
            0.8129032258064516,
            0.8064516129032258,
            0.7935483870967742,
            0.8193548387096774,
            0.7806451612903226,
            0.8064516129032258,
            0.8193548387096774,
            0.8064516129032258,
            0.7419354838709677,
            0.8,
            0.7741935483870968,
            0.7483870967741935,
            0.7935483870967741,
            0.7741935483870968,
            0.7290322580645161,
            0.7806451612903225,
            0.7870967741935484,
            0.8,
            0.7741935483870968,
            0.7806451612903226,
            0.7612903225806451,
            0.8064516129032258,
            0.767741935483871,
            0.8,
            0.8,
            0.8258064516129032,
            0.8064516129032258,
            0.767741935483871,
            0.7354838709677419,
            0.8064516129032258,
            0.8129032258064516,
            0.8258064516129032,
            0.7870967741935484,
            0.832258064516129,
            0.8064516129032258,
            0.8258064516129032,
            0.7612903225806452,
            0.8064516129032258,
            0.8129032258064516,
            0.8129032258064516,
            0.8,
            0.8,
            0.7935483870967742,
            0.832258064516129,
            0.7354838709677419,
            0.7483870967741935,
            0.7548387096774193,
            0.7483870967741935,
            0.735483870967742,
            0.8,
            0.8258064516129032,
            0.7806451612903226,
            0.7741935483870968,
            0.8,
            0.7870967741935484,
            0.7290322580645161,
            0.767741935483871,
            0.7806451612903226,
            0.8,
            0.8064516129032258,
            0.7870967741935484,
            0.8193548387096774,
            0.7419354838709677,
            0.7741935483870968,
            0.7741935483870968,
            0.7612903225806451,
            0.7806451612903226,
            0.8129032258064516,
            0.7935483870967742,
            0.7741935483870968,
            0.7806451612903226,
            0.7870967741935484,
            0.767741935483871,
            0.8129032258064516,
            0.7741935483870968,
            0.8129032258064516,
            0.7935483870967742,
            0.8129032258064516,
            0.7806451612903225,
            0.7870967741935483,
            0.7677419354838709,
            0.7935483870967742,
            0.7354838709677419,
            0.8193548387096774,
            0.735483870967742,
            0.8064516129032258,
            0.8387096774193548,
            0.7483870967741935,
            0.7290322580645161,
            0.7612903225806451,
            0.8129032258064516,
            0.7548387096774192,
            0.7483870967741935,
            0.7612903225806452,
            0.832258064516129,
            0.8193548387096774,
            0.7870967741935484,
            0.7935483870967742,
            0.7612903225806451,
            0.7935483870967742,
            0.7806451612903226,
            0.7677419354838709,
            0.7612903225806451,
            0.7483870967741935,
            0.7870967741935483,
            0.8709677419354838,
            0.7612903225806452,
            0.7741935483870968,
            0.7419354838709677,
            0.7677419354838709,
            0.7548387096774193,
            0.7741935483870968,
            0.8,
            0.7483870967741936,
            0.7419354838709676,
            0.8193548387096774,
            0.7548387096774193,
            0.8129032258064516,
            0.7161290322580645,
            0.7935483870967742,
            0.8387096774193548,
            0.7935483870967741,
            0.8387096774193548,
            0.8064516129032258,
            0.7806451612903225,
            0.8,
            0.8064516129032258,
            0.8387096774193548,
            0.8064516129032258,
            0.832258064516129,
            0.7677419354838709,
            0.767741935483871,
            0.832258064516129,
            0.8129032258064516,
            0.7548387096774193,
            0.7806451612903226,
            0.8129032258064516,
            0.7870967741935483,
            0.7677419354838709,
            0.7612903225806452,
            0.8258064516129032,
            0.832258064516129,
            0.7806451612903225,
            0.8,
            0.8,
            0.7935483870967742,
            0.7741935483870968,
            0.8193548387096774,
            0.7741935483870968,
            0.7612903225806452,
            0.8258064516129032,
            0.8258064516129032,
            0.7612903225806452,
            0.7870967741935483,
            0.8129032258064516,
            0.7870967741935483,
            0.8,
            0.8,
            0.7870967741935484,
            0.8193548387096774,
            0.8387096774193548,
            0.7870967741935484,
            0.7483870967741935,
            0.7548387096774193,
            0.8,
            0.8,
            0.8064516129032258,
            0.8580645161290322,
            0.8,
            0.7419354838709677,
            0.7806451612903226,
            0.8064516129032258,
            0.8129032258064516,
            0.8258064516129032,
            0.7935483870967742,
            0.7935483870967742,
            0.8516129032258064,
            0.7612903225806452,
            0.7612903225806451,
            0.8064516129032258,
            0.7612903225806451,
            0.8193548387096774,
            0.7290322580645161,
            0.7806451612903226,
            0.767741935483871,
            0.7612903225806451,
            0.7677419354838708,
            0.8129032258064516,
            0.7548387096774192,
            0.7806451612903226,
            0.8064516129032258,
            0.7677419354838709,
            0.7354838709677418,
            0.7483870967741936,
            0.7612903225806451,
            0.7806451612903226,
            0.7677419354838709,
            0.7612903225806451,
            0.7870967741935483,
            0.7741935483870968,
            0.7548387096774193,
            0.7612903225806451,
            0.7870967741935483,
            0.7870967741935483,
            0.7806451612903225,
            0.761290322580645,
            0.7870967741935483,
            0.696774193548387,
            0.7677419354838709,
            0.7870967741935484,
            0.7741935483870968,
            0.7548387096774193,
            0.8129032258064516,
            0.8193548387096774,
            0.7806451612903225,
            0.8,
            0.7806451612903225,
            0.767741935483871,
            0.7806451612903226,
            0.8064516129032258,
            0.7806451612903225,
            0.8258064516129032,
            0.8,
            0.8258064516129032,
            0.8129032258064516,
            0.8064516129032258,
            0.8193548387096774,
            0.7677419354838709,
            0.7548387096774193,
            0.8129032258064516,
            0.7741935483870968,
            0.7806451612903226,
            0.7935483870967742,
            0.8129032258064516,
            0.7419354838709676,
            0.7935483870967742,
            0.7870967741935484,
            0.7935483870967741,
            0.7419354838709677,
            0.8129032258064516,
            0.8258064516129032,
            0.7870967741935483,
            0.7870967741935484,
            0.7806451612903225,
            0.7419354838709677,
            0.7870967741935484,
            0.7741935483870968,
            0.8,
            0.7677419354838709,
            0.8451612903225806,
            0.8064516129032258,
            0.8064516129032258,
            0.8,
            0.7612903225806451,
            0.7935483870967741,
            0.7548387096774193,
            0.7741935483870968,
            0.8,
            0.8193548387096774,
            0.7806451612903225,
            0.8129032258064516,
            0.7741935483870968,
            0.7935483870967741,
            0.7870967741935483,
            0.7548387096774194,
            0.7419354838709676,
            0.7419354838709677,
            0.7935483870967742,
            0.7161290322580645,
            0.8064516129032258,
            0.7935483870967742,
            0.7999999999999999,
            0.7870967741935483,
            0.7741935483870968,
            0.8,
            0.8129032258064516,
            0.8129032258064516,
            0.8,
            0.7806451612903226,
            0.8129032258064516,
            0.8709677419354838,
            0.7935483870967742,
            0.7612903225806452,
            0.7806451612903225,
            0.7677419354838709,
            0.8387096774193548,
            0.7870967741935484,
            0.8,
            0.8064516129032258,
            0.7870967741935483,
            0.7870967741935484,
            0.7741935483870968,
            0.7935483870967741,
            0.8258064516129032,
            0.7741935483870968,
            0.8129032258064516,
            0.7612903225806451,
            0.7806451612903225,
            0.8258064516129032,
            0.8129032258064516,
            0.7741935483870968,
            0.7870967741935483,
            0.8129032258064516,
            0.8129032258064516,
            0.8258064516129032,
            0.8129032258064516,
            0.7935483870967742,
            0.735483870967742,
            0.7548387096774193,
            0.7419354838709677,
            0.7548387096774192,
            0.8064516129032258,
            0.7612903225806451,
            0.7870967741935484,
            0.7419354838709677,
            0.8387096774193548,
            0.7806451612903226,
            0.7677419354838709,
            0.7354838709677418,
            0.7612903225806452,
            0.7161290322580645,
            0.7354838709677419,
            0.7419354838709676,
            0.8,
            0.8064516129032258,
            0.7612903225806452,
            0.735483870967742,
            0.7806451612903225,
            0.7032258064516128,
            0.8193548387096774,
            0.8064516129032258,
            0.8193548387096774,
            0.8387096774193548,
            0.7935483870967742,
            0.7806451612903225,
            0.7290322580645161,
            0.7935483870967742,
            0.7935483870967742,
            0.7870967741935484,
            0.864516129032258,
            0.7806451612903225
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.7935483870967742,
           0.8,
           0.8193548387096774,
           0.7935483870967742,
           0.7741935483870966,
           0.7806451612903225,
           0.7935483870967742,
           0.8,
           0.8,
           0.8,
           0.7935483870967742,
           0.8064516129032258,
           0.7935483870967742,
           0.7806451612903225,
           0.8,
           0.7419354838709677,
           0.7677419354838708,
           0.7741935483870966,
           0.7935483870967742,
           0.7935483870967742,
           0.7677419354838708,
           0.7741935483870966,
           0.7870967741935484,
           0.7935483870967742,
           0.8,
           0.7935483870967742,
           0.8129032258064516,
           0.7612903225806451,
           0.7935483870967742,
           0.8,
           0.8064516129032258,
           0.7741935483870966,
           0.7935483870967742,
           0.7935483870967742,
           0.8064516129032258,
           0.7806451612903226,
           0.8064516129032258,
           0.8,
           0.8064516129032258,
           0.7483870967741935,
           0.8193548387096774,
           0.8,
           0.7677419354838708,
           0.8,
           0.7419354838709677,
           0.8,
           0.7935483870967742,
           0.8193548387096774,
           0.8193548387096774,
           0.7935483870967742,
           0.8,
           0.7935483870967742,
           0.7741935483870966,
           0.7806451612903225,
           0.7935483870967742,
           0.7935483870967742,
           0.7741935483870966,
           0.7935483870967742,
           0.8064516129032258,
           0.7677419354838708,
           0.8193548387096774,
           0.8,
           0.8,
           0.7935483870967742,
           0.7935483870967742,
           0.8064516129032258,
           0.7935483870967742,
           0.7677419354838708,
           0.761290322580645,
           0.7548387096774192,
           0.7935483870967742,
           0.7806451612903225,
           0.7935483870967742,
           0.7935483870967742,
           0.7677419354838708,
           0.7548387096774193,
           0.8387096774193548,
           0.8064516129032258,
           0.7870967741935483,
           0.8387096774193548,
           0.8258064516129032,
           0.8387096774193548,
           0.7935483870967742,
           0.8129032258064516,
           0.8258064516129032,
           0.7870967741935484,
           0.8,
           0.7935483870967742,
           0.8,
           0.7741935483870968,
           0.7612903225806451,
           0.8129032258064516,
           0.7870967741935483,
           0.8,
           0.8064516129032258,
           0.8193548387096774,
           0.8258064516129032,
           0.7612903225806451,
           0.8064516129032258,
           0.832258064516129,
           0.7999999999999999,
           0.7677419354838709,
           0.8387096774193548,
           0.7741935483870968,
           0.8,
           0.7612903225806451,
           0.8451612903225806,
           0.7548387096774193,
           0.7935483870967742,
           0.767741935483871,
           0.832258064516129,
           0.8129032258064516,
           0.8064516129032258,
           0.8064516129032258,
           0.7870967741935484,
           0.7741935483870968,
           0.7935483870967742,
           0.7870967741935483,
           0.761290322580645,
           0.7870967741935483,
           0.7870967741935484,
           0.8129032258064516,
           0.832258064516129,
           0.8,
           0.832258064516129,
           0.7806451612903226,
           0.7741935483870968,
           0.7935483870967742,
           0.7870967741935483,
           0.8064516129032258,
           0.767741935483871,
           0.8064516129032258,
           0.832258064516129,
           0.7935483870967742,
           0.8129032258064516,
           0.8,
           0.7741935483870968,
           0.7935483870967742,
           0.7612903225806451,
           0.832258064516129,
           0.8258064516129032,
           0.8516129032258064,
           0.7741935483870968,
           0.8451612903225806,
           0.7741935483870968,
           0.8129032258064516,
           0.7870967741935484,
           0.7225806451612903,
           0.7870967741935484,
           0.7677419354838708,
           0.8258064516129032,
           0.7870967741935483,
           0.8258064516129032,
           0.8129032258064516,
           0.8129032258064516,
           0.7354838709677418,
           0.8258064516129032,
           0.7806451612903226,
           0.8516129032258064,
           0.832258064516129,
           0.8,
           0.7548387096774193,
           0.7806451612903226,
           0.7999999999999999,
           0.8258064516129032,
           0.7677419354838709,
           0.8129032258064516,
           0.7548387096774193,
           0.7806451612903226,
           0.8451612903225806,
           0.7290322580645161,
           0.8129032258064516,
           0.8,
           0.8387096774193548,
           0.7096774193548387,
           0.7741935483870968,
           0.7870967741935484,
           0.7548387096774193,
           0.8387096774193548,
           0.7806451612903226,
           0.832258064516129,
           0.7870967741935483,
           0.7935483870967742,
           0.7419354838709677,
           0.7870967741935484,
           0.7870967741935484,
           0.8129032258064516,
           0.8129032258064516,
           0.8387096774193548,
           0.8516129032258064,
           0.7870967741935484,
           0.7677419354838709,
           0.7870967741935484,
           0.7612903225806452,
           0.8064516129032258,
           0.8064516129032258,
           0.7741935483870968,
           0.7548387096774192,
           0.7806451612903225,
           0.7612903225806452,
           0.7612903225806452,
           0.7870967741935484,
           0.7870967741935483,
           0.7806451612903226,
           0.8064516129032258,
           0.7806451612903226,
           0.7935483870967741,
           0.8387096774193548,
           0.7870967741935484,
           0.7741935483870968,
           0.7677419354838708,
           0.7548387096774193,
           0.7741935483870968,
           0.8387096774193548,
           0.7741935483870968,
           0.7806451612903226,
           0.7870967741935484,
           0.7290322580645161,
           0.7935483870967741,
           0.7483870967741936,
           0.7870967741935483,
           0.7483870967741936,
           0.8129032258064516,
           0.8387096774193548,
           0.832258064516129,
           0.7354838709677419,
           0.7548387096774194,
           0.7225806451612902,
           0.7741935483870968,
           0.729032258064516,
           0.7612903225806451,
           0.7741935483870966,
           0.7612903225806451,
           0.7935483870967741,
           0.8193548387096774,
           0.8064516129032258,
           0.7999999999999999,
           0.7806451612903225,
           0.7548387096774193,
           0.832258064516129,
           0.7612903225806451,
           0.7741935483870968,
           0.7870967741935484,
           0.7483870967741935,
           0.7935483870967742,
           0.7612903225806451,
           0.8580645161290322,
           0.7870967741935483,
           0.8064516129032258,
           0.8064516129032258,
           0.7612903225806451,
           0.8064516129032258,
           0.7935483870967742,
           0.7806451612903226,
           0.7483870967741935,
           0.8,
           0.8,
           0.7677419354838709,
           0.832258064516129,
           0.7548387096774193,
           0.7612903225806451,
           0.8387096774193548,
           0.8064516129032258,
           0.8193548387096774,
           0.7483870967741936,
           0.7935483870967742,
           0.7741935483870968,
           0.7806451612903225,
           0.7741935483870968,
           0.7870967741935483,
           0.7935483870967742,
           0.7935483870967742,
           0.7483870967741936,
           0.7677419354838709,
           0.7806451612903226,
           0.7548387096774193,
           0.8,
           0.7999999999999999,
           0.8064516129032258,
           0.7935483870967742,
           0.8,
           0.7419354838709677,
           0.7612903225806451,
           0.767741935483871,
           0.7483870967741935,
           0.7612903225806451,
           0.8064516129032258,
           0.7612903225806451,
           0.7999999999999999,
           0.8129032258064516,
           0.7225806451612902,
           0.729032258064516,
           0.7935483870967742,
           0.7741935483870968,
           0.7677419354838709,
           0.7806451612903226,
           0.8,
           0.832258064516129,
           0.8064516129032258,
           0.7612903225806451,
           0.8,
           0.7870967741935484,
           0.7806451612903226,
           0.767741935483871,
           0.8129032258064516,
           0.7548387096774194,
           0.8064516129032258,
           0.8,
           0.8129032258064516,
           0.8064516129032258,
           0.7935483870967742,
           0.8193548387096774,
           0.7806451612903226,
           0.8064516129032258,
           0.8193548387096774,
           0.8064516129032258,
           0.7419354838709677,
           0.8,
           0.7741935483870968,
           0.7483870967741935,
           0.7935483870967741,
           0.7741935483870968,
           0.7290322580645161,
           0.7806451612903225,
           0.7870967741935484,
           0.8,
           0.7741935483870968,
           0.7806451612903226,
           0.7612903225806451,
           0.8064516129032258,
           0.767741935483871,
           0.8,
           0.8,
           0.8258064516129032,
           0.8064516129032258,
           0.767741935483871,
           0.7354838709677419,
           0.8064516129032258,
           0.8129032258064516,
           0.8258064516129032,
           0.7870967741935484,
           0.832258064516129,
           0.8064516129032258,
           0.8258064516129032,
           0.7612903225806452,
           0.8064516129032258,
           0.8129032258064516,
           0.8129032258064516,
           0.8,
           0.8,
           0.7935483870967742,
           0.832258064516129,
           0.7354838709677419,
           0.7483870967741935,
           0.7548387096774193,
           0.7483870967741935,
           0.735483870967742,
           0.8,
           0.8258064516129032,
           0.7806451612903226,
           0.7741935483870968,
           0.8,
           0.7870967741935484,
           0.7290322580645161,
           0.767741935483871,
           0.7806451612903226,
           0.8,
           0.8064516129032258,
           0.7870967741935484,
           0.8193548387096774,
           0.7419354838709677,
           0.7741935483870968,
           0.7741935483870968,
           0.7612903225806451,
           0.7806451612903226,
           0.8129032258064516,
           0.7935483870967742,
           0.7741935483870968,
           0.7806451612903226,
           0.7870967741935484,
           0.767741935483871,
           0.8129032258064516,
           0.7741935483870968,
           0.8129032258064516,
           0.7935483870967742,
           0.8129032258064516,
           0.7806451612903225,
           0.7870967741935483,
           0.7677419354838709,
           0.7935483870967742,
           0.7354838709677419,
           0.8193548387096774,
           0.735483870967742,
           0.8064516129032258,
           0.8387096774193548,
           0.7483870967741935,
           0.7290322580645161,
           0.7612903225806451,
           0.8129032258064516,
           0.7548387096774192,
           0.7483870967741935,
           0.7612903225806452,
           0.832258064516129,
           0.8193548387096774,
           0.7870967741935484,
           0.7935483870967742,
           0.7612903225806451,
           0.7935483870967742,
           0.7806451612903226,
           0.7677419354838709,
           0.7612903225806451,
           0.7483870967741935,
           0.7870967741935483,
           0.8709677419354838,
           0.7612903225806452,
           0.7741935483870968,
           0.7419354838709677,
           0.7677419354838709,
           0.7548387096774193,
           0.7741935483870968,
           0.8,
           0.7483870967741936,
           0.7419354838709676,
           0.8193548387096774,
           0.7548387096774193,
           0.8129032258064516,
           0.7161290322580645,
           0.7935483870967742,
           0.8387096774193548,
           0.7935483870967741,
           0.8387096774193548,
           0.8064516129032258,
           0.7806451612903225,
           0.8,
           0.8064516129032258,
           0.8387096774193548,
           0.8064516129032258,
           0.832258064516129,
           0.7677419354838709,
           0.767741935483871,
           0.832258064516129,
           0.8129032258064516,
           0.7548387096774193,
           0.7806451612903226,
           0.8129032258064516,
           0.7870967741935483,
           0.7677419354838709,
           0.7612903225806452,
           0.8258064516129032,
           0.832258064516129,
           0.7806451612903225,
           0.8,
           0.8,
           0.7935483870967742,
           0.7741935483870968,
           0.8193548387096774,
           0.7741935483870968,
           0.7612903225806452,
           0.8258064516129032,
           0.8258064516129032,
           0.7612903225806452,
           0.7870967741935483,
           0.8129032258064516,
           0.7870967741935483,
           0.8,
           0.8,
           0.7870967741935484,
           0.8193548387096774,
           0.8387096774193548,
           0.7870967741935484,
           0.7483870967741935,
           0.7548387096774193,
           0.8,
           0.8,
           0.8064516129032258,
           0.8580645161290322,
           0.8,
           0.7419354838709677,
           0.7806451612903226,
           0.8064516129032258,
           0.8129032258064516,
           0.8258064516129032,
           0.7935483870967742,
           0.7935483870967742,
           0.8516129032258064,
           0.7612903225806452,
           0.7612903225806451,
           0.8064516129032258,
           0.7612903225806451,
           0.8193548387096774,
           0.7290322580645161,
           0.7806451612903226,
           0.767741935483871,
           0.7612903225806451,
           0.7677419354838708,
           0.8129032258064516,
           0.7548387096774192,
           0.7806451612903226,
           0.8064516129032258,
           0.7677419354838709,
           0.7354838709677418,
           0.7483870967741936,
           0.7612903225806451,
           0.7806451612903226,
           0.7677419354838709,
           0.7612903225806451,
           0.7870967741935483,
           0.7741935483870968,
           0.7548387096774193,
           0.7612903225806451,
           0.7870967741935483,
           0.7870967741935483,
           0.7806451612903225,
           0.761290322580645,
           0.7870967741935483,
           0.696774193548387,
           0.7677419354838709,
           0.7870967741935484,
           0.7741935483870968,
           0.7548387096774193,
           0.8129032258064516,
           0.8193548387096774,
           0.7806451612903225,
           0.8,
           0.7806451612903225,
           0.767741935483871,
           0.7806451612903226,
           0.8064516129032258,
           0.7806451612903225,
           0.8258064516129032,
           0.8,
           0.8258064516129032,
           0.8129032258064516,
           0.8064516129032258,
           0.8193548387096774,
           0.7677419354838709,
           0.7548387096774193,
           0.8129032258064516,
           0.7741935483870968,
           0.7806451612903226,
           0.7935483870967742,
           0.8129032258064516,
           0.7419354838709676,
           0.7935483870967742,
           0.7870967741935484,
           0.7935483870967741,
           0.7419354838709677,
           0.8129032258064516,
           0.8258064516129032,
           0.7870967741935483,
           0.7870967741935484,
           0.7806451612903225,
           0.7419354838709677,
           0.7870967741935484,
           0.7741935483870968,
           0.8,
           0.7677419354838709,
           0.8451612903225806,
           0.8064516129032258,
           0.8064516129032258,
           0.8,
           0.7612903225806451,
           0.7935483870967741,
           0.7548387096774193,
           0.7741935483870968,
           0.8,
           0.8193548387096774,
           0.7806451612903225,
           0.8129032258064516,
           0.7741935483870968,
           0.7935483870967741,
           0.7870967741935483,
           0.7548387096774194,
           0.7419354838709676,
           0.7419354838709677,
           0.7935483870967742,
           0.7161290322580645,
           0.8064516129032258,
           0.7935483870967742,
           0.7999999999999999,
           0.7870967741935483,
           0.7741935483870968,
           0.8,
           0.8129032258064516,
           0.8129032258064516,
           0.8,
           0.7806451612903226,
           0.8129032258064516,
           0.8709677419354838,
           0.7935483870967742,
           0.7612903225806452,
           0.7806451612903225,
           0.7677419354838709,
           0.8387096774193548,
           0.7870967741935484,
           0.8,
           0.8064516129032258,
           0.7870967741935483,
           0.7870967741935484,
           0.7741935483870968,
           0.7935483870967741,
           0.8258064516129032,
           0.7741935483870968,
           0.8129032258064516,
           0.7612903225806451,
           0.7806451612903225,
           0.8258064516129032,
           0.8129032258064516,
           0.7741935483870968,
           0.7870967741935483,
           0.8129032258064516,
           0.8129032258064516,
           0.8258064516129032,
           0.8129032258064516,
           0.7935483870967742,
           0.735483870967742,
           0.7548387096774193,
           0.7419354838709677,
           0.7548387096774192,
           0.8064516129032258,
           0.7612903225806451,
           0.7870967741935484,
           0.7419354838709677,
           0.8387096774193548,
           0.7806451612903226,
           0.7677419354838709,
           0.7354838709677418,
           0.7612903225806452,
           0.7161290322580645,
           0.7354838709677419,
           0.7419354838709676,
           0.8,
           0.8064516129032258,
           0.7612903225806452,
           0.735483870967742,
           0.7806451612903225,
           0.7032258064516128,
           0.8193548387096774,
           0.8064516129032258,
           0.8193548387096774,
           0.8387096774193548,
           0.7935483870967742,
           0.7806451612903225,
           0.7290322580645161,
           0.7935483870967742,
           0.7935483870967742,
           0.7870967741935484,
           0.864516129032258,
           0.7806451612903225
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "mean_test_score"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0bdca8a3-4f85-43ba-84e8-fa07616f7643\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0bdca8a3-4f85-43ba-84e8-fa07616f7643\")) {                    Plotly.newPlot(                        \"0bdca8a3-4f85-43ba-84e8-fa07616f7643\",                        [{\"dimensions\":[{\"label\":\"ccp_alpha\",\"values\":[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]},{\"label\":\"criterion\",\"values\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]},{\"label\":\"max_depth\",\"values\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0,15.0]},{\"label\":\"max_features\",\"values\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]},{\"label\":\"min_samples_leaf\",\"values\":[1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4,1,1,1,2,2,2,4,4,4]},{\"label\":\"min_samples_split\",\"values\":[2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10,2,5,10]},{\"label\":\"mean_test_score\",\"values\":[0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.8,0.8193548387096774,0.7935483870967742,0.7741935483870966,0.7806451612903225,0.7935483870967742,0.8,0.8,0.8,0.7935483870967742,0.8064516129032258,0.7935483870967742,0.7806451612903225,0.8,0.7419354838709677,0.7677419354838708,0.7741935483870966,0.7935483870967742,0.7935483870967742,0.7677419354838708,0.7741935483870966,0.7870967741935484,0.7935483870967742,0.8,0.7935483870967742,0.8129032258064516,0.7612903225806451,0.7935483870967742,0.8,0.8064516129032258,0.7741935483870966,0.7935483870967742,0.7935483870967742,0.8064516129032258,0.7806451612903226,0.8064516129032258,0.8,0.8064516129032258,0.7483870967741935,0.8193548387096774,0.8,0.7677419354838708,0.8,0.7419354838709677,0.8,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8,0.7935483870967742,0.7741935483870966,0.7806451612903225,0.7935483870967742,0.7935483870967742,0.7741935483870966,0.7935483870967742,0.8064516129032258,0.7677419354838708,0.8193548387096774,0.8,0.8,0.7935483870967742,0.7935483870967742,0.8064516129032258,0.7935483870967742,0.7677419354838708,0.761290322580645,0.7548387096774192,0.7935483870967742,0.7806451612903225,0.7935483870967742,0.7935483870967742,0.7677419354838708,0.7548387096774193,0.8387096774193548,0.8064516129032258,0.7870967741935483,0.8387096774193548,0.8258064516129032,0.8387096774193548,0.7935483870967742,0.8129032258064516,0.8258064516129032,0.7870967741935484,0.8,0.7935483870967742,0.8,0.7741935483870968,0.7612903225806451,0.8129032258064516,0.7870967741935483,0.8,0.8064516129032258,0.8193548387096774,0.8258064516129032,0.7612903225806451,0.8064516129032258,0.832258064516129,0.7999999999999999,0.7677419354838709,0.8387096774193548,0.7741935483870968,0.8,0.7612903225806451,0.8451612903225806,0.7548387096774193,0.7935483870967742,0.767741935483871,0.832258064516129,0.8129032258064516,0.8064516129032258,0.8064516129032258,0.7870967741935484,0.7741935483870968,0.7935483870967742,0.7870967741935483,0.761290322580645,0.7870967741935483,0.7870967741935484,0.8129032258064516,0.832258064516129,0.8,0.832258064516129,0.7806451612903226,0.7741935483870968,0.7935483870967742,0.7870967741935483,0.8064516129032258,0.767741935483871,0.8064516129032258,0.832258064516129,0.7935483870967742,0.8129032258064516,0.8,0.7741935483870968,0.7935483870967742,0.7612903225806451,0.832258064516129,0.8258064516129032,0.8516129032258064,0.7741935483870968,0.8451612903225806,0.7741935483870968,0.8129032258064516,0.7870967741935484,0.7225806451612903,0.7870967741935484,0.7677419354838708,0.8258064516129032,0.7870967741935483,0.8258064516129032,0.8129032258064516,0.8129032258064516,0.7354838709677418,0.8258064516129032,0.7806451612903226,0.8516129032258064,0.832258064516129,0.8,0.7548387096774193,0.7806451612903226,0.7999999999999999,0.8258064516129032,0.7677419354838709,0.8129032258064516,0.7548387096774193,0.7806451612903226,0.8451612903225806,0.7290322580645161,0.8129032258064516,0.8,0.8387096774193548,0.7096774193548387,0.7741935483870968,0.7870967741935484,0.7548387096774193,0.8387096774193548,0.7806451612903226,0.832258064516129,0.7870967741935483,0.7935483870967742,0.7419354838709677,0.7870967741935484,0.7870967741935484,0.8129032258064516,0.8129032258064516,0.8387096774193548,0.8516129032258064,0.7870967741935484,0.7677419354838709,0.7870967741935484,0.7612903225806452,0.8064516129032258,0.8064516129032258,0.7741935483870968,0.7548387096774192,0.7806451612903225,0.7612903225806452,0.7612903225806452,0.7870967741935484,0.7870967741935483,0.7806451612903226,0.8064516129032258,0.7806451612903226,0.7935483870967741,0.8387096774193548,0.7870967741935484,0.7741935483870968,0.7677419354838708,0.7548387096774193,0.7741935483870968,0.8387096774193548,0.7741935483870968,0.7806451612903226,0.7870967741935484,0.7290322580645161,0.7935483870967741,0.7483870967741936,0.7870967741935483,0.7483870967741936,0.8129032258064516,0.8387096774193548,0.832258064516129,0.7354838709677419,0.7548387096774194,0.7225806451612902,0.7741935483870968,0.729032258064516,0.7612903225806451,0.7741935483870966,0.7612903225806451,0.7935483870967741,0.8193548387096774,0.8064516129032258,0.7999999999999999,0.7806451612903225,0.7548387096774193,0.832258064516129,0.7612903225806451,0.7741935483870968,0.7870967741935484,0.7483870967741935,0.7935483870967742,0.7612903225806451,0.8580645161290322,0.7870967741935483,0.8064516129032258,0.8064516129032258,0.7612903225806451,0.8064516129032258,0.7935483870967742,0.7806451612903226,0.7483870967741935,0.8,0.8,0.7677419354838709,0.832258064516129,0.7548387096774193,0.7612903225806451,0.8387096774193548,0.8064516129032258,0.8193548387096774,0.7483870967741936,0.7935483870967742,0.7741935483870968,0.7806451612903225,0.7741935483870968,0.7870967741935483,0.7935483870967742,0.7935483870967742,0.7483870967741936,0.7677419354838709,0.7806451612903226,0.7548387096774193,0.8,0.7999999999999999,0.8064516129032258,0.7935483870967742,0.8,0.7419354838709677,0.7612903225806451,0.767741935483871,0.7483870967741935,0.7612903225806451,0.8064516129032258,0.7612903225806451,0.7999999999999999,0.8129032258064516,0.7225806451612902,0.729032258064516,0.7935483870967742,0.7741935483870968,0.7677419354838709,0.7806451612903226,0.8,0.832258064516129,0.8064516129032258,0.7612903225806451,0.8,0.7870967741935484,0.7806451612903226,0.767741935483871,0.8129032258064516,0.7548387096774194,0.8064516129032258,0.8,0.8129032258064516,0.8064516129032258,0.7935483870967742,0.8193548387096774,0.7806451612903226,0.8064516129032258,0.8193548387096774,0.8064516129032258,0.7419354838709677,0.8,0.7741935483870968,0.7483870967741935,0.7935483870967741,0.7741935483870968,0.7290322580645161,0.7806451612903225,0.7870967741935484,0.8,0.7741935483870968,0.7806451612903226,0.7612903225806451,0.8064516129032258,0.767741935483871,0.8,0.8,0.8258064516129032,0.8064516129032258,0.767741935483871,0.7354838709677419,0.8064516129032258,0.8129032258064516,0.8258064516129032,0.7870967741935484,0.832258064516129,0.8064516129032258,0.8258064516129032,0.7612903225806452,0.8064516129032258,0.8129032258064516,0.8129032258064516,0.8,0.8,0.7935483870967742,0.832258064516129,0.7354838709677419,0.7483870967741935,0.7548387096774193,0.7483870967741935,0.735483870967742,0.8,0.8258064516129032,0.7806451612903226,0.7741935483870968,0.8,0.7870967741935484,0.7290322580645161,0.767741935483871,0.7806451612903226,0.8,0.8064516129032258,0.7870967741935484,0.8193548387096774,0.7419354838709677,0.7741935483870968,0.7741935483870968,0.7612903225806451,0.7806451612903226,0.8129032258064516,0.7935483870967742,0.7741935483870968,0.7806451612903226,0.7870967741935484,0.767741935483871,0.8129032258064516,0.7741935483870968,0.8129032258064516,0.7935483870967742,0.8129032258064516,0.7806451612903225,0.7870967741935483,0.7677419354838709,0.7935483870967742,0.7354838709677419,0.8193548387096774,0.735483870967742,0.8064516129032258,0.8387096774193548,0.7483870967741935,0.7290322580645161,0.7612903225806451,0.8129032258064516,0.7548387096774192,0.7483870967741935,0.7612903225806452,0.832258064516129,0.8193548387096774,0.7870967741935484,0.7935483870967742,0.7612903225806451,0.7935483870967742,0.7806451612903226,0.7677419354838709,0.7612903225806451,0.7483870967741935,0.7870967741935483,0.8709677419354838,0.7612903225806452,0.7741935483870968,0.7419354838709677,0.7677419354838709,0.7548387096774193,0.7741935483870968,0.8,0.7483870967741936,0.7419354838709676,0.8193548387096774,0.7548387096774193,0.8129032258064516,0.7161290322580645,0.7935483870967742,0.8387096774193548,0.7935483870967741,0.8387096774193548,0.8064516129032258,0.7806451612903225,0.8,0.8064516129032258,0.8387096774193548,0.8064516129032258,0.832258064516129,0.7677419354838709,0.767741935483871,0.832258064516129,0.8129032258064516,0.7548387096774193,0.7806451612903226,0.8129032258064516,0.7870967741935483,0.7677419354838709,0.7612903225806452,0.8258064516129032,0.832258064516129,0.7806451612903225,0.8,0.8,0.7935483870967742,0.7741935483870968,0.8193548387096774,0.7741935483870968,0.7612903225806452,0.8258064516129032,0.8258064516129032,0.7612903225806452,0.7870967741935483,0.8129032258064516,0.7870967741935483,0.8,0.8,0.7870967741935484,0.8193548387096774,0.8387096774193548,0.7870967741935484,0.7483870967741935,0.7548387096774193,0.8,0.8,0.8064516129032258,0.8580645161290322,0.8,0.7419354838709677,0.7806451612903226,0.8064516129032258,0.8129032258064516,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8516129032258064,0.7612903225806452,0.7612903225806451,0.8064516129032258,0.7612903225806451,0.8193548387096774,0.7290322580645161,0.7806451612903226,0.767741935483871,0.7612903225806451,0.7677419354838708,0.8129032258064516,0.7548387096774192,0.7806451612903226,0.8064516129032258,0.7677419354838709,0.7354838709677418,0.7483870967741936,0.7612903225806451,0.7806451612903226,0.7677419354838709,0.7612903225806451,0.7870967741935483,0.7741935483870968,0.7548387096774193,0.7612903225806451,0.7870967741935483,0.7870967741935483,0.7806451612903225,0.761290322580645,0.7870967741935483,0.696774193548387,0.7677419354838709,0.7870967741935484,0.7741935483870968,0.7548387096774193,0.8129032258064516,0.8193548387096774,0.7806451612903225,0.8,0.7806451612903225,0.767741935483871,0.7806451612903226,0.8064516129032258,0.7806451612903225,0.8258064516129032,0.8,0.8258064516129032,0.8129032258064516,0.8064516129032258,0.8193548387096774,0.7677419354838709,0.7548387096774193,0.8129032258064516,0.7741935483870968,0.7806451612903226,0.7935483870967742,0.8129032258064516,0.7419354838709676,0.7935483870967742,0.7870967741935484,0.7935483870967741,0.7419354838709677,0.8129032258064516,0.8258064516129032,0.7870967741935483,0.7870967741935484,0.7806451612903225,0.7419354838709677,0.7870967741935484,0.7741935483870968,0.8,0.7677419354838709,0.8451612903225806,0.8064516129032258,0.8064516129032258,0.8,0.7612903225806451,0.7935483870967741,0.7548387096774193,0.7741935483870968,0.8,0.8193548387096774,0.7806451612903225,0.8129032258064516,0.7741935483870968,0.7935483870967741,0.7870967741935483,0.7548387096774194,0.7419354838709676,0.7419354838709677,0.7935483870967742,0.7161290322580645,0.8064516129032258,0.7935483870967742,0.7999999999999999,0.7870967741935483,0.7741935483870968,0.8,0.8129032258064516,0.8129032258064516,0.8,0.7806451612903226,0.8129032258064516,0.8709677419354838,0.7935483870967742,0.7612903225806452,0.7806451612903225,0.7677419354838709,0.8387096774193548,0.7870967741935484,0.8,0.8064516129032258,0.7870967741935483,0.7870967741935484,0.7741935483870968,0.7935483870967741,0.8258064516129032,0.7741935483870968,0.8129032258064516,0.7612903225806451,0.7806451612903225,0.8258064516129032,0.8129032258064516,0.7741935483870968,0.7870967741935483,0.8129032258064516,0.8129032258064516,0.8258064516129032,0.8129032258064516,0.7935483870967742,0.735483870967742,0.7548387096774193,0.7419354838709677,0.7548387096774192,0.8064516129032258,0.7612903225806451,0.7870967741935484,0.7419354838709677,0.8387096774193548,0.7806451612903226,0.7677419354838709,0.7354838709677418,0.7612903225806452,0.7161290322580645,0.7354838709677419,0.7419354838709676,0.8,0.8064516129032258,0.7612903225806452,0.735483870967742,0.7806451612903225,0.7032258064516128,0.8193548387096774,0.8064516129032258,0.8193548387096774,0.8387096774193548,0.7935483870967742,0.7806451612903225,0.7290322580645161,0.7935483870967742,0.7935483870967742,0.7870967741935484,0.864516129032258,0.7806451612903225]}],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"line\":{\"color\":[0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.7935483870967742,0.8,0.8193548387096774,0.7935483870967742,0.7741935483870966,0.7806451612903225,0.7935483870967742,0.8,0.8,0.8,0.7935483870967742,0.8064516129032258,0.7935483870967742,0.7806451612903225,0.8,0.7419354838709677,0.7677419354838708,0.7741935483870966,0.7935483870967742,0.7935483870967742,0.7677419354838708,0.7741935483870966,0.7870967741935484,0.7935483870967742,0.8,0.7935483870967742,0.8129032258064516,0.7612903225806451,0.7935483870967742,0.8,0.8064516129032258,0.7741935483870966,0.7935483870967742,0.7935483870967742,0.8064516129032258,0.7806451612903226,0.8064516129032258,0.8,0.8064516129032258,0.7483870967741935,0.8193548387096774,0.8,0.7677419354838708,0.8,0.7419354838709677,0.8,0.7935483870967742,0.8193548387096774,0.8193548387096774,0.7935483870967742,0.8,0.7935483870967742,0.7741935483870966,0.7806451612903225,0.7935483870967742,0.7935483870967742,0.7741935483870966,0.7935483870967742,0.8064516129032258,0.7677419354838708,0.8193548387096774,0.8,0.8,0.7935483870967742,0.7935483870967742,0.8064516129032258,0.7935483870967742,0.7677419354838708,0.761290322580645,0.7548387096774192,0.7935483870967742,0.7806451612903225,0.7935483870967742,0.7935483870967742,0.7677419354838708,0.7548387096774193,0.8387096774193548,0.8064516129032258,0.7870967741935483,0.8387096774193548,0.8258064516129032,0.8387096774193548,0.7935483870967742,0.8129032258064516,0.8258064516129032,0.7870967741935484,0.8,0.7935483870967742,0.8,0.7741935483870968,0.7612903225806451,0.8129032258064516,0.7870967741935483,0.8,0.8064516129032258,0.8193548387096774,0.8258064516129032,0.7612903225806451,0.8064516129032258,0.832258064516129,0.7999999999999999,0.7677419354838709,0.8387096774193548,0.7741935483870968,0.8,0.7612903225806451,0.8451612903225806,0.7548387096774193,0.7935483870967742,0.767741935483871,0.832258064516129,0.8129032258064516,0.8064516129032258,0.8064516129032258,0.7870967741935484,0.7741935483870968,0.7935483870967742,0.7870967741935483,0.761290322580645,0.7870967741935483,0.7870967741935484,0.8129032258064516,0.832258064516129,0.8,0.832258064516129,0.7806451612903226,0.7741935483870968,0.7935483870967742,0.7870967741935483,0.8064516129032258,0.767741935483871,0.8064516129032258,0.832258064516129,0.7935483870967742,0.8129032258064516,0.8,0.7741935483870968,0.7935483870967742,0.7612903225806451,0.832258064516129,0.8258064516129032,0.8516129032258064,0.7741935483870968,0.8451612903225806,0.7741935483870968,0.8129032258064516,0.7870967741935484,0.7225806451612903,0.7870967741935484,0.7677419354838708,0.8258064516129032,0.7870967741935483,0.8258064516129032,0.8129032258064516,0.8129032258064516,0.7354838709677418,0.8258064516129032,0.7806451612903226,0.8516129032258064,0.832258064516129,0.8,0.7548387096774193,0.7806451612903226,0.7999999999999999,0.8258064516129032,0.7677419354838709,0.8129032258064516,0.7548387096774193,0.7806451612903226,0.8451612903225806,0.7290322580645161,0.8129032258064516,0.8,0.8387096774193548,0.7096774193548387,0.7741935483870968,0.7870967741935484,0.7548387096774193,0.8387096774193548,0.7806451612903226,0.832258064516129,0.7870967741935483,0.7935483870967742,0.7419354838709677,0.7870967741935484,0.7870967741935484,0.8129032258064516,0.8129032258064516,0.8387096774193548,0.8516129032258064,0.7870967741935484,0.7677419354838709,0.7870967741935484,0.7612903225806452,0.8064516129032258,0.8064516129032258,0.7741935483870968,0.7548387096774192,0.7806451612903225,0.7612903225806452,0.7612903225806452,0.7870967741935484,0.7870967741935483,0.7806451612903226,0.8064516129032258,0.7806451612903226,0.7935483870967741,0.8387096774193548,0.7870967741935484,0.7741935483870968,0.7677419354838708,0.7548387096774193,0.7741935483870968,0.8387096774193548,0.7741935483870968,0.7806451612903226,0.7870967741935484,0.7290322580645161,0.7935483870967741,0.7483870967741936,0.7870967741935483,0.7483870967741936,0.8129032258064516,0.8387096774193548,0.832258064516129,0.7354838709677419,0.7548387096774194,0.7225806451612902,0.7741935483870968,0.729032258064516,0.7612903225806451,0.7741935483870966,0.7612903225806451,0.7935483870967741,0.8193548387096774,0.8064516129032258,0.7999999999999999,0.7806451612903225,0.7548387096774193,0.832258064516129,0.7612903225806451,0.7741935483870968,0.7870967741935484,0.7483870967741935,0.7935483870967742,0.7612903225806451,0.8580645161290322,0.7870967741935483,0.8064516129032258,0.8064516129032258,0.7612903225806451,0.8064516129032258,0.7935483870967742,0.7806451612903226,0.7483870967741935,0.8,0.8,0.7677419354838709,0.832258064516129,0.7548387096774193,0.7612903225806451,0.8387096774193548,0.8064516129032258,0.8193548387096774,0.7483870967741936,0.7935483870967742,0.7741935483870968,0.7806451612903225,0.7741935483870968,0.7870967741935483,0.7935483870967742,0.7935483870967742,0.7483870967741936,0.7677419354838709,0.7806451612903226,0.7548387096774193,0.8,0.7999999999999999,0.8064516129032258,0.7935483870967742,0.8,0.7419354838709677,0.7612903225806451,0.767741935483871,0.7483870967741935,0.7612903225806451,0.8064516129032258,0.7612903225806451,0.7999999999999999,0.8129032258064516,0.7225806451612902,0.729032258064516,0.7935483870967742,0.7741935483870968,0.7677419354838709,0.7806451612903226,0.8,0.832258064516129,0.8064516129032258,0.7612903225806451,0.8,0.7870967741935484,0.7806451612903226,0.767741935483871,0.8129032258064516,0.7548387096774194,0.8064516129032258,0.8,0.8129032258064516,0.8064516129032258,0.7935483870967742,0.8193548387096774,0.7806451612903226,0.8064516129032258,0.8193548387096774,0.8064516129032258,0.7419354838709677,0.8,0.7741935483870968,0.7483870967741935,0.7935483870967741,0.7741935483870968,0.7290322580645161,0.7806451612903225,0.7870967741935484,0.8,0.7741935483870968,0.7806451612903226,0.7612903225806451,0.8064516129032258,0.767741935483871,0.8,0.8,0.8258064516129032,0.8064516129032258,0.767741935483871,0.7354838709677419,0.8064516129032258,0.8129032258064516,0.8258064516129032,0.7870967741935484,0.832258064516129,0.8064516129032258,0.8258064516129032,0.7612903225806452,0.8064516129032258,0.8129032258064516,0.8129032258064516,0.8,0.8,0.7935483870967742,0.832258064516129,0.7354838709677419,0.7483870967741935,0.7548387096774193,0.7483870967741935,0.735483870967742,0.8,0.8258064516129032,0.7806451612903226,0.7741935483870968,0.8,0.7870967741935484,0.7290322580645161,0.767741935483871,0.7806451612903226,0.8,0.8064516129032258,0.7870967741935484,0.8193548387096774,0.7419354838709677,0.7741935483870968,0.7741935483870968,0.7612903225806451,0.7806451612903226,0.8129032258064516,0.7935483870967742,0.7741935483870968,0.7806451612903226,0.7870967741935484,0.767741935483871,0.8129032258064516,0.7741935483870968,0.8129032258064516,0.7935483870967742,0.8129032258064516,0.7806451612903225,0.7870967741935483,0.7677419354838709,0.7935483870967742,0.7354838709677419,0.8193548387096774,0.735483870967742,0.8064516129032258,0.8387096774193548,0.7483870967741935,0.7290322580645161,0.7612903225806451,0.8129032258064516,0.7548387096774192,0.7483870967741935,0.7612903225806452,0.832258064516129,0.8193548387096774,0.7870967741935484,0.7935483870967742,0.7612903225806451,0.7935483870967742,0.7806451612903226,0.7677419354838709,0.7612903225806451,0.7483870967741935,0.7870967741935483,0.8709677419354838,0.7612903225806452,0.7741935483870968,0.7419354838709677,0.7677419354838709,0.7548387096774193,0.7741935483870968,0.8,0.7483870967741936,0.7419354838709676,0.8193548387096774,0.7548387096774193,0.8129032258064516,0.7161290322580645,0.7935483870967742,0.8387096774193548,0.7935483870967741,0.8387096774193548,0.8064516129032258,0.7806451612903225,0.8,0.8064516129032258,0.8387096774193548,0.8064516129032258,0.832258064516129,0.7677419354838709,0.767741935483871,0.832258064516129,0.8129032258064516,0.7548387096774193,0.7806451612903226,0.8129032258064516,0.7870967741935483,0.7677419354838709,0.7612903225806452,0.8258064516129032,0.832258064516129,0.7806451612903225,0.8,0.8,0.7935483870967742,0.7741935483870968,0.8193548387096774,0.7741935483870968,0.7612903225806452,0.8258064516129032,0.8258064516129032,0.7612903225806452,0.7870967741935483,0.8129032258064516,0.7870967741935483,0.8,0.8,0.7870967741935484,0.8193548387096774,0.8387096774193548,0.7870967741935484,0.7483870967741935,0.7548387096774193,0.8,0.8,0.8064516129032258,0.8580645161290322,0.8,0.7419354838709677,0.7806451612903226,0.8064516129032258,0.8129032258064516,0.8258064516129032,0.7935483870967742,0.7935483870967742,0.8516129032258064,0.7612903225806452,0.7612903225806451,0.8064516129032258,0.7612903225806451,0.8193548387096774,0.7290322580645161,0.7806451612903226,0.767741935483871,0.7612903225806451,0.7677419354838708,0.8129032258064516,0.7548387096774192,0.7806451612903226,0.8064516129032258,0.7677419354838709,0.7354838709677418,0.7483870967741936,0.7612903225806451,0.7806451612903226,0.7677419354838709,0.7612903225806451,0.7870967741935483,0.7741935483870968,0.7548387096774193,0.7612903225806451,0.7870967741935483,0.7870967741935483,0.7806451612903225,0.761290322580645,0.7870967741935483,0.696774193548387,0.7677419354838709,0.7870967741935484,0.7741935483870968,0.7548387096774193,0.8129032258064516,0.8193548387096774,0.7806451612903225,0.8,0.7806451612903225,0.767741935483871,0.7806451612903226,0.8064516129032258,0.7806451612903225,0.8258064516129032,0.8,0.8258064516129032,0.8129032258064516,0.8064516129032258,0.8193548387096774,0.7677419354838709,0.7548387096774193,0.8129032258064516,0.7741935483870968,0.7806451612903226,0.7935483870967742,0.8129032258064516,0.7419354838709676,0.7935483870967742,0.7870967741935484,0.7935483870967741,0.7419354838709677,0.8129032258064516,0.8258064516129032,0.7870967741935483,0.7870967741935484,0.7806451612903225,0.7419354838709677,0.7870967741935484,0.7741935483870968,0.8,0.7677419354838709,0.8451612903225806,0.8064516129032258,0.8064516129032258,0.8,0.7612903225806451,0.7935483870967741,0.7548387096774193,0.7741935483870968,0.8,0.8193548387096774,0.7806451612903225,0.8129032258064516,0.7741935483870968,0.7935483870967741,0.7870967741935483,0.7548387096774194,0.7419354838709676,0.7419354838709677,0.7935483870967742,0.7161290322580645,0.8064516129032258,0.7935483870967742,0.7999999999999999,0.7870967741935483,0.7741935483870968,0.8,0.8129032258064516,0.8129032258064516,0.8,0.7806451612903226,0.8129032258064516,0.8709677419354838,0.7935483870967742,0.7612903225806452,0.7806451612903225,0.7677419354838709,0.8387096774193548,0.7870967741935484,0.8,0.8064516129032258,0.7870967741935483,0.7870967741935484,0.7741935483870968,0.7935483870967741,0.8258064516129032,0.7741935483870968,0.8129032258064516,0.7612903225806451,0.7806451612903225,0.8258064516129032,0.8129032258064516,0.7741935483870968,0.7870967741935483,0.8129032258064516,0.8129032258064516,0.8258064516129032,0.8129032258064516,0.7935483870967742,0.735483870967742,0.7548387096774193,0.7419354838709677,0.7548387096774192,0.8064516129032258,0.7612903225806451,0.7870967741935484,0.7419354838709677,0.8387096774193548,0.7806451612903226,0.7677419354838709,0.7354838709677418,0.7612903225806452,0.7161290322580645,0.7354838709677419,0.7419354838709676,0.8,0.8064516129032258,0.7612903225806452,0.735483870967742,0.7806451612903225,0.7032258064516128,0.8193548387096774,0.8064516129032258,0.8193548387096774,0.8387096774193548,0.7935483870967742,0.7806451612903225,0.7290322580645161,0.7935483870967742,0.7935483870967742,0.7870967741935484,0.864516129032258,0.7806451612903225],\"coloraxis\":\"coloraxis\"},\"name\":\"\",\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"mean_test_score\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0bdca8a3-4f85-43ba-84e8-fa07616f7643');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'decisiontreeclassifier__ccp_alpha': 0.0001,\n",
       " 'decisiontreeclassifier__criterion': 'gini',\n",
       " 'decisiontreeclassifier__max_depth': 10,\n",
       " 'decisiontreeclassifier__max_features': 'log2',\n",
       " 'decisiontreeclassifier__min_samples_leaf': 4,\n",
       " 'decisiontreeclassifier__min_samples_split': 5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search(DecisionTreeClassifier(), X, y, hyperparams = params_dt, scoring=f2, scale=MinMaxScaler())\n",
    "best_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbba6a",
   "metadata": {},
   "source": [
    "## Best models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8d61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_best = pd.DataFrame(columns=['Split/Fold', 'Method', 'Algorithm', 'Scaling', 'Accuracy', 'Recall', 'F1-score', 'F2-score', 'Training time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1cf42233",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = {preproc(k): v for k, v in best_svm.items()}\n",
    "best_lr = {preproc(k): v for k, v in best_lr.items()}\n",
    "best_dt = {preproc(k): v for k, v in best_dt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf1613a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split/Fold</th>\n",
       "      <th>Method</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.008994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.009999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.018996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.019998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.017995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.006994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.006996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.006001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cross-validation</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.006994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Split/Fold            Method            Algorithm         Scaling  Accuracy  \\\n",
       "0          1  Cross-validation                  SVM  StandardScaler  0.838710   \n",
       "1          2  Cross-validation                  SVM  StandardScaler  0.903226   \n",
       "2          3  Cross-validation                  SVM  StandardScaler  0.870968   \n",
       "3          4  Cross-validation                  SVM  StandardScaler  0.903226   \n",
       "4          5  Cross-validation                  SVM  StandardScaler  0.806452   \n",
       "0          1  Cross-validation  Logistic Regression    MinMaxScaler  0.838710   \n",
       "1          2  Cross-validation  Logistic Regression    MinMaxScaler  0.870968   \n",
       "2          3  Cross-validation  Logistic Regression    MinMaxScaler  0.870968   \n",
       "3          4  Cross-validation  Logistic Regression    MinMaxScaler  0.870968   \n",
       "4          5  Cross-validation  Logistic Regression    MinMaxScaler  0.774194   \n",
       "0          1  Cross-validation        Decision Tree    MinMaxScaler  0.903226   \n",
       "1          2  Cross-validation        Decision Tree    MinMaxScaler  0.838710   \n",
       "2          3  Cross-validation        Decision Tree    MinMaxScaler  0.903226   \n",
       "3          4  Cross-validation        Decision Tree    MinMaxScaler  0.870968   \n",
       "4          5  Cross-validation        Decision Tree    MinMaxScaler  0.741935   \n",
       "\n",
       "     Recall  F1-score  F2-score  Training time  \n",
       "0  1.000000  0.909091  0.961538       0.008994  \n",
       "1  1.000000  0.943396  0.976563       0.008000  \n",
       "2  0.960000  0.923077  0.944882       0.008000  \n",
       "3  1.000000  0.941176  0.975610       0.005998  \n",
       "4  0.833333  0.869565  0.847458       0.009999  \n",
       "0  1.000000  0.909091  0.961538       0.015998  \n",
       "1  0.960000  0.923077  0.944882       0.018996  \n",
       "2  0.960000  0.923077  0.944882       0.019998  \n",
       "3  0.916667  0.916667  0.916667       0.019997  \n",
       "4  0.750000  0.837209  0.782609       0.017995  \n",
       "0  0.960000  0.941176  0.952381       0.006994  \n",
       "1  0.880000  0.897959  0.887097       0.006996  \n",
       "2  0.960000  0.941176  0.952381       0.006001  \n",
       "3  1.000000  0.923077  0.967742       0.007000  \n",
       "4  0.750000  0.818182  0.775862       0.006994  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_best = pd.concat([res_best, cross_validation(\"SVM\", SVC(**best_svm), X, y, scale=StandardScaler())])\n",
    "res_best = pd.concat([res_best, cross_validation(\"Logistic Regression\", LogisticRegression(**best_lr), X, y, scale=MinMaxScaler())])\n",
    "res_best = pd.concat([res_best, cross_validation(\"Decision Tree\", DecisionTreeClassifier(**best_dt), X, y, scale=MinMaxScaler())])\n",
    "res_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4251e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Training time', ylabel='Algorithm'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=\"Algorithm\", x=\"F2-score\", palette=sns_palette,\n",
    "            data=res_best)\n",
    "plt.show()\n",
    "sns.boxplot(y=\"Algorithm\", x=\"Training time\", palette=sns_palette,\n",
    "            data=res_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15fccf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">F2-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.907093</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.079690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.910116</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.073080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.053966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F2-score                              \n",
       "                          min      mean       max       std\n",
       "Algorithm                                                  \n",
       "Decision Tree        0.775862  0.907093  0.967742  0.079690\n",
       "Logistic Regression  0.782609  0.910116  0.961538  0.073080\n",
       "SVM                  0.847458  0.941210  0.976563  0.053966"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_best.groupby(['Algorithm']).agg({'F2-score': [ 'min', 'mean', 'max', 'std']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
