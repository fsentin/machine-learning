{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and functions to build NN's with different features for testing\n",
    "Structure: Inputlayer-(FCL-ActivationLayer)-(FCL-ActivationLayer)...(FCL-ActivationLayer)-OutputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "np.random.seed(1)\n",
    "tensorflow.random.set_seed(1)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Class for layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for fully connected layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation method:\n",
    "\n",
    "#### Input: \n",
    "$\\underline{x}$ - ROW vector of size $1 $ x $i$  \n",
    "    \n",
    "#### output of one layer:  \n",
    "  \n",
    "$ \\underline{y} =  \\underline{x \\cdot W} + \\underline{b}  $ - vector of size $j$ x $1$\n",
    "\n",
    "#### Used:\n",
    "     \n",
    "Weights: $W$ - matrix of size $i$ x $j$  \n",
    "bias: $ \\underline{b} $ COLUMN vector of length $j$ x $1$. One $b_j$ for each $y_j$   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward porpagation method:  \n",
    "  \n",
    "#### Input:  \n",
    "    \n",
    "$\\underline{output\\_error} = \\frac{d\\underline{E}}{d\\underline{y}} $ is a vector, of shape $1$ x $j$, with elements $\\frac{d\\underline{E}}{d\\underline{y_j}}$  \n",
    "  \n",
    "LearningRate $ \\alpha $  \n",
    "  \n",
    "$E$ is the loss function, calculated as (in class ...)  \n",
    "  \n",
    "\n",
    "#### Output:  \n",
    "  \n",
    "Weights_error = $ \\frac{d\\underline{E}}{d\\underline{W}} = \\underline{x}^T \\cdot \\frac{d\\underline{E}}{d\\underline{y}} $ is a matrix of size $i$ x $j$  \n",
    "\n",
    "#### Used:\n",
    "  \n",
    "$\\underline{bias\\_error} = output\\_error$ - vector length $1$ x $b$    \n",
    "  \n",
    "$ \\underline{input\\_error}: \\frac{d\\underline{E}}{d\\underline{x}} = \\frac{d\\underline{E}}{d\\underline{y}} \\cdot W^T $ - vector of size $1$ x $i$ \n",
    "  \n",
    "derivation on paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer():\n",
    "    # input_size (i) = number of input neurons\n",
    "    # output_size (j) = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        #start by setting random weights and biases\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns y_vector for a given x_vector\n",
    "    def forward_propagation(self, input_data):\n",
    "        #reshape x into a row vector\n",
    "        self.input = input_data.reshape(1,-1)\n",
    "        #calculate output of layer: \n",
    "        # y = xw+b\n",
    "        #print (\"weight size \") \n",
    "        #print(self.weights.size) \n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. \n",
    "    # Returns input_error=dE/dx.\n",
    "   \n",
    "    \n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        # dE/dx - this is the output of this function\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        \n",
    "     \n",
    "        # (dE/dW = x^T * dE/dy)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # db/dx = dE/dy = output_error\n",
    "\n",
    "        # update weights\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        #update biases\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for activation layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input:   \n",
    "activation function for the forward propagation  \n",
    "the derivative of the activation function for the backward propagation  \n",
    "\n",
    "### forward_propagation:  \n",
    "   \n",
    "input: $\\underline{y}$ of size $j$ x $1$  \n",
    "output: $ \\underline{y_{act}} $  of size $j$ x $1$\n",
    "  \n",
    "### backward_propagation: \n",
    "   \n",
    "input: $ \\frac{d\\underline{E}}{d\\underline{y}} $ of size $1$ x $j$  \n",
    "output: $ \\frac{d\\underline{E}}{d\\underline{y_{act}}} * f'(\\underline{y_{act}}) $ of size $1$ x $j$  \n",
    "this is element-wise multiplication, so $\\frac{d\\underline{E}}{d{y_{act, k}}}$ * $f'(y_{act, k})$ etc.  \n",
    "the derivative of the activation function is with respect to its input, in this case $y_{act}$ (see calculation below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        # y activated\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error for a given output_error\n",
    "    # learning_rate is not used because the learnable parameters are in the FC layers\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        #element-wise multiplication\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions and their derivatives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$  \n",
    "  \n",
    "$\\tanh'(x) = \\frac{{(e^x+e^{-x})(e^x+e^{-x})-(e^x-e^{-x})(e^x-e^{-x})}}{{(e^x+e^{-x})^2}} = \\frac{{(e^x+e^{-x})^2-(e^x-e^{-x})^2}}{{(e^x+e^{-x})^2}}= 1-\\frac{{(e^x-e^{-x})^2}}{{(e^x+e^{-x})^2}} = 1 - \\tanh^2(x)$  \n",
    "\n",
    "$relu'(0) = 1$ since $\\lim_{{x \\to 0^-}} = 1 $ and $ \\lim_{{x \\to 0^+}} = 0$ , we have to pick, by convention we pick 1  \n",
    "  \n",
    "$sigmoid(x) = \\frac{1}{1 + e^{-x}}$  \n",
    "  \n",
    "$sigmoid'(x) = \\frac{e^{-x}}{(e^{-x}+1)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "    \n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    sigmoid_x = sigmoid(x)\n",
    "    return sigmoid_x * (1 - sigmoid_x)\n",
    "\n",
    "activation_functions = [tanh, tanh_prime, relu, relu_prime]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and its derivative  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy\n",
    "$loss(y_{true}, y_{pred}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_{true}^{(i)} \\log(y_{pred}^{(i)}) + (1 - y_{true}^{(i)}) \\log(1 - y_{pred}^{(i)}) \\right) $\n",
    "\n",
    "$\\frac{d loss(y_{true}, y_{pred})}{dy_{pred}}= \\frac{y_{pred} - y_{true}}{y_{pred} \\cdot (1 - y_{pred}) \\cdot j }$  \n",
    "  \n",
    "$j$ is the size of vector  $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15  # small constant to avoid division by zero\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip predictions to avoid numerical instability\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def cross_entropy_prime(y_true, y_pred):\n",
    "    epsilon = 1e-15  # small constant to avoid division by zero\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip predictions to avoid numerical instability\n",
    "    return (y_pred - y_true) / (y_pred * (1 - y_pred) * y_true.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "        self.configuration= None\n",
    "        self.act = None\n",
    "        self.act_prime = None\n",
    "        self.epoch_error = None\n",
    "      \n",
    "    \n",
    "  \n",
    "    def set_activation_index(self, a):\n",
    "        self.act = a\n",
    "    \n",
    "    def set_activation_prime_index(self, b):\n",
    "        self.act_prime = b\n",
    "\n",
    "    #add the configuration\n",
    "    def set_config(self, c):\n",
    "        self.configuration = c\n",
    "        \n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set up the loss functions\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "\n",
    "    # train the network \n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            #print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
    "            self.epoch_error = err\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different configurations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input and management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = pd.read_csv('breast-cancer-diagnostic.shuf.lrn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lrn['class']\n",
    "X = lrn.drop(['class', 'ID'], axis=1)\n",
    "x_total = X.to_numpy()\n",
    "y_total = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_total, test_size=0.1, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "#scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metric F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(actual_labels, predicted_values):\n",
    "    assert len(actual_labels) == len(predicted_values), \"Number of labels and predictions should match.\"\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if actual_labels[i] == 1 and predicted_values[i] == 1:\n",
    "            true_positives += 1\n",
    "        elif actual_labels[i] == 0 and predicted_values[i] == 1:\n",
    "            false_positives += 1\n",
    "        elif actual_labels[i] == 1 and predicted_values[i] == 0:\n",
    "            false_negatives += 1\n",
    "    if true_positives + false_positives > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best structure for our network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10, 50, 100 or 200 nodes per layer  \n",
    "2, 3 or 4 hidden layers  \n",
    "0.3, 0.5 or 0.9 treshold  \n",
    "2 activation functions for hidden layers: tanh and relu  \n",
    "\n",
    "generate all combinations  \n",
    "calculate f1 for each  \n",
    "find best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(nums):\n",
    "    if len(nums) == 0:\n",
    "        return [[]]  # Base case: an empty list has one permutation, an empty list itself\n",
    "    \n",
    "    permutations = []\n",
    "    \n",
    "    for i in range(len(nums)):\n",
    "        current_num = nums[i]\n",
    "        remaining_nums = nums[:i] + nums[i+1:]\n",
    "        \n",
    "        for permutation in generate_permutations(remaining_nums):\n",
    "            permutations.append([current_num] + permutation)\n",
    "    \n",
    "    return permutations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_configurations(nodes_per_layer_options, layers):\n",
    "    configs = []\n",
    "    node_options = generate_permutations(nodes_per_layer_options)\n",
    "    for i in layers:\n",
    "        # Extract the first i columns and store unique values in a set\n",
    "        unique_values = set(tuple(row[:i]) for row in node_options)\n",
    "        # Convert the set back to a list of lists\n",
    "        extracted_columns = [list(values) for values in unique_values]\n",
    "        configs.append(extracted_columns)\n",
    "        #Print the extracted columns\n",
    "        #print(i, \"layers\")\n",
    "        #for column in extracted_columns:\n",
    "            #print( column)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(nodes, activation_index, activation_prime_index):\n",
    "    net = Network()\n",
    "    net.set_activation_index(activation_index)\n",
    "    net.set_activation_prime_index(activation_prime_index)\n",
    "    net.add(FCLayer(x_total.shape[1], nodes[0]))  # input layer\n",
    "    #print(\"input layer \", nodes[0] )\n",
    "\n",
    "    for i in range(len(nodes)-1):\n",
    "        net.add(FCLayer(nodes[i], nodes[i+1])) \n",
    "        #print(\"hidden layer in\", nodes[i], \"out\", nodes[i+1] )\n",
    "        net.add(ActivationLayer(activation_functions[activation_index], activation_functions[activation_prime_index]))\n",
    " \n",
    "    net.add(FCLayer(nodes[-1], 1))  # output layer\n",
    "    net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "    #print(\"output layer \", nodes[-1] )\n",
    "  \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_options = [10, 50, 100, 200]\n",
    "layer_options = [2, 3, 4]\n",
    "treshold = [0.5, 0.8, 0.9]\n",
    "configurations= create_configurations(nodes_options, layer_options)\n",
    "nns_tanh = []\n",
    "nns_relu = []\n",
    "data = []\n",
    "top = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tanh(c_i):\n",
    "    #activation_functions = [tanh, tanh_prime, relu, relu_prime]\n",
    "    for x in c_i:\n",
    "        c = create_network(x,0,1)\n",
    "        c.set_config(x)\n",
    "        nns_tanh.append(c)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relu (c_i):\n",
    "      for x in c_i:\n",
    "        c = create_network(x, 2, 3)\n",
    "        c.set_config(x)\n",
    "        nns_relu.append(c)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(nns):\n",
    "    epochs = [10, 25, 50]\n",
    "    for epoch in epochs:\n",
    "            for nets in nns:\n",
    "                nets.use(cross_entropy, cross_entropy_prime)\n",
    "                nets.fit(x_train, y_train, epochs=epoch, learning_rate=0.1)\n",
    "                pred = nets.predict(x_val)\n",
    "\n",
    "                # Convert the list of arrays to a numpy array\n",
    "                predicted = np.array([arr[0][0] for arr in pred])\n",
    "\n",
    "                for tresh in treshold:\n",
    "                    y_pred = np.where(predicted >= tresh, 1, 0)\n",
    "                    f1_s = f1_score(y_val*1, y_pred)\n",
    "                    top.append([nets.configuration, nets.act, nets.act_prime, tresh, epoch, f1_s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\991229207.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layer_options)):\n",
    "   \n",
    "    generate_tanh(configurations[i])\n",
    "    generate_relu(configurations[i])\n",
    "\n",
    "    hyperparameter_search(nns_tanh)\n",
    "    hyperparameter_search(nns_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top).to_csv('breast-cancer-top2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 50], 0, 1, 0.5, 10, 1.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_top = sorted(top, key=lambda x: x[-1], reverse=True)\n",
    "#sorted_top\n",
    "tops = sorted_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#0 = config, 1= act, 2=act_prime, 3 = tresh, 4 = epochs\n",
    "mdl = create_network(tops[0], tops[1], tops[2])\n",
    "mdl.use(cross_entropy, cross_entropy_prime)\n",
    "mdl.fit(x_test, y_test, tops[4], 0.1)\n",
    "prd = mdl.predict(x_test)\n",
    "pr = np.array([arr[0][0] for arr in prd])\n",
    "bi = np.where(pr >= tops[3], 1, 0)\n",
    "f1_best = calculate_f1(y_test, bi)\n",
    "print(f1_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9600000000000001"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_network(tops[0], tops[1], tops[2])\n",
    "model.use(cross_entropy, cross_entropy_prime)\n",
    "model.fit(x_train, y_train, tops[4], 0.1)\n",
    "y_pred = model.predict(x_test)\n",
    "y_prd = np.array([arr[0][0] for arr in y_pred])\n",
    "y_pred = np.where(y_prd >= tops[3], 1, 0)\n",
    "f1_score(y_test*1, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_validation(x, y, tops):\n",
    "    kfold = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    # enumerate splits\n",
    "    for (train, test) in kfold.split(x,y):\n",
    "        x_tr = x[train]\n",
    "        y_tr = y[train]\n",
    "        x_tst = x[test]\n",
    "        y_tst = y[test]\n",
    "        model = create_network(tops[0], tops[1], tops[2])\n",
    "        model.use(cross_entropy, cross_entropy_prime)\n",
    "        model.fit(x_tr, y_tr, tops[4], 0.1)\n",
    "        y_pred = model.predict(x_tst)\n",
    "        y_prd = np.array([arr[0][0] for arr in y_pred])\n",
    "        y_pred = np.where(y_prd >= tops[3], 1, 0)\n",
    "        scores.append(f1_score(y_tst*1, y_pred))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9565217391304348, 1.0, 0.9743589743589743, 0.9444444444444444, 0.9545454545454545]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9659741224958616"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validation(x_train, y_train, tops)\n",
    "print(scores)\n",
    "np.mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daria\\AppData\\Local\\Temp\\ipykernel_14408\\4204664436.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.7870\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8478\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8913\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8315\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9565\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8641\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8478\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9130\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.9457\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9565\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# Define the function to create the model\n",
    "def create_model(units = 200):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='tanh', input_dim=len(x_train[0])))\n",
    "    model.add(Dense(units, activation='tanh'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cr = cross_validate(model, x_train, y_train, cv=5)\n",
    "\n",
    "f1 = calculate_f1(y_test, y_pred)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943478274345398"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr['test_score'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra: how we chose the learning-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 hand\n",
      "0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#uncommented the print epoch error, see errors from epoch to epoch\n",
    "\n",
    "hand = create_network(tops[0], tops[1], tops[2])\n",
    "hand.use(cross_entropy, cross_entropy_prime)\n",
    "\n",
    "\n",
    "# Define the range of learning rates to explore\n",
    "learning_rates = np.logspace(-6, 0, num=10)\n",
    "\n",
    "# Initialize lists to store learning rates and corresponding losses\n",
    "lr_values = []\n",
    "loss_values = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    \n",
    "    # Train your neural network for a few epochs with the current learning rate\n",
    "    hand.fit(x_train, y_train, 50, lr)\n",
    "    # Calculate and store the loss/error after each epoch\n",
    "    loss = hand.epoch_error\n",
    "    lr_values.append(lr)\n",
    "    loss_values.append(loss)\n",
    "\n",
    "# Plot the learning rate vs. loss curve\n",
    "plt.plot(lr_values, loss_values)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ph=hand.predict(x_test)\n",
    "# Convert the list of arrays to a numpy array\n",
    "predicted_ph = np.array([arr[0][0] for arr in ph])\n",
    "##add threshold\n",
    "binary_ph = np.where(predicted_ph >= 0.5, 1, 0)\n",
    "print(\"f1 hand\")\n",
    "f1 = calculate_f1(y_test, binary_ph)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
