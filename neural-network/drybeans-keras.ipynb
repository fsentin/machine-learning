{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "np.random.seed(1)\n",
    "tensorflow.random.set_seed(1)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input and management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_data = pd.read_excel(\"Dry_Bean_Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = DB_data.drop(['Class'], axis=1) # everything except the class # DB for Dry beans\n",
    "y = DB_data['Class']  # only the class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Reshape the input vector to a 2D array with a single column\n",
    "input_array = [[item] for item in y]\n",
    "\n",
    "# Fit and transform the input array using the encoder\n",
    "y_total = encoder.fit_transform(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=0.1, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "#scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SEKER', 'BARBUNYA', 'BOMBAY', 'CALI', 'HOROZ', 'SIRA', 'DERMASON'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45230498, -0.56642518, -0.83998333, ...,  1.49283775,\n",
       "         1.80624901,  0.85834145],\n",
       "       [-0.31036032, -0.29539358, -0.14142003, ..., -0.35725861,\n",
       "        -0.54563597,  0.14303312],\n",
       "       [ 2.986967  ,  2.66320004,  2.3909027 , ..., -1.24784071,\n",
       "         0.07350478, -0.23572825],\n",
       "       ...,\n",
       "       [ 0.72137049,  0.87385458,  1.01284472, ..., -1.03144271,\n",
       "        -0.73141171, -0.97885949],\n",
       "       [-0.16323619, -0.06995348, -0.07942365, ..., -0.24691538,\n",
       "        -0.17826263, -0.04219919],\n",
       "       [ 0.66856017,  0.91924172,  1.0724145 , ..., -1.13677331,\n",
       "        -0.99127158, -1.96737601]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38599\\AppData\\Local\\Temp/ipykernel_17116/2427224783.py:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 2s 3ms/step - loss: 0.2914 - accuracy: 0.8991\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "276/276 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8896\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9152\n",
      "276/276 [==============================] - 2s 3ms/step - loss: 0.3182 - accuracy: 0.8896\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9206\n",
      "276/276 [==============================] - 2s 3ms/step - loss: 0.3080 - accuracy: 0.8893\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9147\n",
      "276/276 [==============================] - 2s 3ms/step - loss: 0.3141 - accuracy: 0.8943\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9107\n",
      "276/276 [==============================] - 2s 3ms/step - loss: 0.3075 - accuracy: 0.8923\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9165\n"
     ]
    }
   ],
   "source": [
    "# Define the function to create the model\n",
    "def create_model(units = 200):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='tanh', input_dim=len(x_train[0])))\n",
    "    model.add(Dense(units, activation='tanh'))\n",
    "    model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "#f1_score(y_test, y_pred)\n",
    "cr = cross_validate(model, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9155479788780212"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr['test_score'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
